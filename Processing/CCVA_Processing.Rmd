---
title: "CCVA_Processing"
author: "KEC"
date: "2024-04-04"
output: html_document
editor_options: 
  chunk_output_type: console
---

## CCVA Data Processing

This R markdown prepares data inputs for a Climate Change Vulnerability 
Assessment (CCVA) for water supplies at a selected National Park.

### 1. Setup Workspace

First, install and/or load required packages and functions.

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

source('setup.R')
library("readxl")
library("trend")

```

Define park using 4-digit NPS Unit Code. 
Codes for all parks can be found at: 
<https://www.nps.gov/aboutus/foia/upload/NPS-Unit-List.xlsx>.

```{r park}

park <- "BRCA"

```

### 2. Data import option

Read in data if you've already downloaded it
```{r read_data}

## path to data folder (from project directory)
path <- "data/park/"

# read in data
try(
load(paste0(path, "/", park, "/", park, "_report_data.RData")))
## terra object issue when saving as .RData, so saved as separate .tif
```

###3. Download data

Various climate, hydrology, and geography data are required to generate a CCVA 
for the selected National Park. The following code chunks download and describe 
this data.

##### 3.1. Park boundary

Start by specifying which National Park to obtain data for by assigning the 
"park" variable with the four digit Unit List code. Codes for all parks can be 
found at: <https://www.nps.gov/aboutus/foia/upload/NPS-Unit-List.xlsx>.

Once the park is specified, download the park boundary from the NPS IRMA 
DataStore as an sf object.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}


# Get park geometry and metadata
park_boundary <- getParkBoundary(park = park)
state <- park_boundary$STATE
park_name <- park_boundary$UNIT_NAME
park_name_short <- gsub(" National Park", "", park_name)

# Define report name
report_name <- 
  paste0("Climate Change Vulnerability Assessment for Water Supplies at ",
         park_name)

```

##### 3.2. Watersheds and NHD flowlines

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get watersheds within park boundary
park_watershed <- getWatersheds(aoi = park_boundary, 
  clipped = FALSE,
  save = FALSE)

# Get flowlines within park boundary
park_flowlines <- park_watershed %>%
  dplyr:: summarize() %>%
  mapNHDPlusHR() %>%
  dplyr:: summarize()

```

##### 3.3. Water Supply

###### 3.3.1 Water Supply Database

A water supply system database was created for this project using various NPS
and public databases.  Import the park-specific rows of that database to 
identify key water system information.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# First, read in water supply database
supply_table <- 
  read_excel("data/Water_Supply_Systems/NPS_Water_Systems_Database.xlsx", 
      sheet = 2,
      col_types = 
        c("text", "text", "text", "text", "numeric", "numeric", "text", "text",
          "text", "text", "text", "numeric", "text", "text", "text", "text",
          "numeric", "numeric", "text", "text", "text", "numeric", "text",
          "numeric", "text", "text", "numeric", "text", "text", "date",
          "numeric", "text", "text", "text", "text", "text")) %>%
  janitor::clean_names() %>%
  dplyr::filter(park_name %like% c(park_name_short)) %>%
  mutate(water_system_num = str_extract(water_system_name, pattern = "\\d+$"), 
         water_system_name2 = gsub("[0-9]", "", water_system_name))

# Create supply_table subset with only active supplies
active_supply_table <- 
  supply_table %>%
  dplyr::filter(active %in% "Yes")

```

###### 3.3.2 Park PODs

Park water supplies may be sourced from within or beyond the park boundary. This
chunk pulls in state-reported water supply locations, or points of diversion (PODS)
that occur within a buffer distance of the park boundary. Then, PODs are filtered
to identify specific PODs associated with park water supplies. For some parks, 
the water supply system ID is linked using the water supply database. For 
others, we assume the water supply is any POD owned by NPS within the select buffer.

\*\*\*\*KEC: This assumes POD_state has "OWNER" column and that NPS is 
identified by string "NATIONAL PARK". Should probably update match strings in 
future as other POD databases are brought in.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Now, get state specific points of diversion (POD) (i.e., water supply points)
# EDIT NOTE - Eventually nest into a getPODall function with aoi and dist
# args which then applies the state-specific function.

# Set distance and AOI for POD search
buffer_dist <- .1 # in decimal degrees lat/long

aoi <- 
  park_watershed %>% 
  dplyr::summarize() %>%
  mutate(UNIT_CODE = park)

# Dictionary to map POD functions to states
POD_dict <- c(
  "CA" = getPODCalifornia,
  "CO" = getPODColorado,
  "MT" = getWaterRightsMontana,
  "NV" = getPODNevada,
  "UT" = getPODUtah
)

# Assign POD_state using the condition map
if (state %in% names(POD_dict)) {
  
  POD_state <- POD_dict[[state]](aoi, buffer_dist)  # Pass additional arguments

  } else {
    
  print("No PODs returned.")

  }


# Filter using water supply database to identify PODs associated park water 
# supplies. If table does not have adequate information, select by POD
# owner and location metadata

if(active_supply_table %>% drop_na(water_rights_id) %>% nrow() > 0) {
  
  POD_supply <- POD_state %>%
    #dplyr::filter(WRNUM %in% c("61-893", "2061001M00")) %>%
    dplyr::filter(WRNUM %in% active_supply_table$water_rights_id) %>%
    dplyr::distinct(LOCATION, .keep_all = TRUE) %>%
    dplyr::mutate(
      name = active_supply_table %>% 
        pull (water_system_name)) 
  
} else {
    
  POD_supply <- POD_state %>%
    dplyr::filter(
      OWNER %like% "NATIONAL PARK",
      str_detect(SUMMARY_ST, "A|P")) %>% # approved / perfected applications
      #str_detect(USES,"D|M|O|I")) %>%  # filter by POD use category
    dplyr::distinct(WRNUM,
                    .keep_all = TRUE) %>%
    mutate(name = source)
      
      #if (nrow(Suppliers) >= 1) {
      #  POD_supply <- POD_supply %>%
      #    left_join(., Suppliers, by = WRID)
      #}
}

# All PODS within park
POD_all <- 
  POD_state %>% 
  dplyr::filter(park_right == "Park") %>% 
  dplyr::distinct(WRNUM, .keep_all = TRUE)


```

###### 3.3.3 POD Watersheds

Next, we pull in watersheds that intersect with POD points.


```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get watershed intersecting each watersupply point
watersupply_watershed <- vector("list", nrow(POD_supply))  
  
for(i in 1:nrow(POD_supply)){
  watersupply_watershed[[i]] <- POD_supply[i,] %>% 
  getXYWatersheds(sf = ., coordinates = NULL)
}

watersupply_watershed <- 
  watersupply_watershed %>%
  dplyr::bind_rows() %>% 
  dplyr::distinct(featureid, .keep_all = TRUE) 

# Get flowlines associated with watersupply watershed
watersupply_flowlines <- 
  watersupply_watershed %>%
  dplyr::summarize() %>%
  mapNHDPlusHR()

watersupply_watershed_area <- 
  st_area(dplyr::summarize(watersupply_watershed))


```

##### 3.4. Centroids

Climate futures have been previously compiled for park and Koppen centroids. 
This data was used for selecting divergent climate models that represent a range
of conditions at the park. Here, we import Koppen Climate data and selected
climate models for park centroids.

Source for Koppen-Geiger climate classification maps:

Beck, H. E., Zimmermann, N. E., McVicar, T. R., Vergopolan, N., Berg, A., & 
Wood, E. F. (2018). Present and future KÃ¶ppen-Geiger climate classification maps
at 1-km resolution. Scientific data, 5(1), 1-12.

<https://figshare.com/articles/dataset/Present_and_future_K_ppen-Geiger_climate_classification_maps_at_1-km_resolution/6396959/2>


```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

select_cfs <- get_select_cfs(park_boundary = park_boundary,
                             watersupply_watershed = watersupply_watershed,
                             method = "distance")


```

##### 3.5. Climate data 

Import climate data for park centroid.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}


## Centroid climate data

#get_centroid_climate_data(park = park, save = TRUE) 

# Directory to which files were downloaded.
climate_dir <- paste0("data/park/",park,"/centroid/climate")

# Import centroid climate data
centroid_climate <- 
  base::list.files(climate_dir,full.names = TRUE) %>%
  purrr::map(~ read_csv(.x) %>% 
  dplyr::mutate(
    Unit_ClimateZone = str_remove_all(basename(.x),
    "_(?<=_)(future|historical)\\.csv"))) %>%
  dplyr::bind_rows() %>%
  dplyr::left_join(select_cfs, by = "GCM") %>%
  dplyr::mutate(CF = ifelse(GCM %in% "gridmet.historical","Historical",CF)) %>%
  janitor::clean_names() %>%
  dplyr::select(-c(park, delta_tavg,delta_pr)) %>%
  dplyr::filter(unit_climate_zone == select_cfs$centroid[1])


```

##### 3.6. WBM Data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Download centroid data -- will need to update for each park
# get_centroid_wbm_data(park = park) #CM - comment out for now since files 
# already downloaded
    
## Note, currently getting an error with save = FALSE in function call

wbm_dir <- paste0("data/park/",park,"/centroid/wbm/")

centroid_wbm <- 
  list.files(wbm_dir,full.names = TRUE) %>% 
  purrr::map(~ read_csv(.)) %>% 
  bind_rows() %>%
  left_join(select_cfs, by = "GCM") %>%
  dplyr::mutate(CF = ifelse(GCM %in% "gridmet.historical","Historical",CF)) %>%
  janitor::clean_names() %>%
  dplyr::select(-c(park,lat,lon,delta_tavg,delta_pr, period)) %>%
  dplyr::filter(unit_climate_zone == select_cfs$centroid[1])


# Also import 30 year WBM stats
## list of variables to map function over
variables <- c("runoff", "accumswe", "AET", "soil_water")
cf <- select_cfs$GCM
scen <- select_cfs$CF

wbm_30y <- 
  map(variables, 
      ~get30yearWBMGridMET(aoi = st_buffer(park_boundary, 0.2),
                          variable = .x,
                          cf = cf,
                          save = FALSE
                         #path = "data/all",
                         #filename_prefix = "BRCA"
                          )
      )

wbm_30y <- terra::rast(wbm_30y)
# manually save for now, but going to save variable with report data .Rdata
 writeRaster(
      wbm_30y,
      filename =  "data/park/BRCA/BRCA_wbm_30yr_annual_rasters.tif",
      overwrite = TRUE
    )

### In the future, we'll get WBM data for the watersupply watershed.
# Here is the code to do that as of now -- can probably be sped up.
 
# First download wbm data for the watersupply watershed.
# This took an hour and 10 minutes for the BRCA watershed, so only do this
# again if necessary.
 
ws_wbm <- 
  get_wbm_aoi(park,
              aoi = watersupply_watershed %>% 
                st_union(), 
              aoi_name = "watersupply_watershed", download = FALSE) 
                      # rename if joining to other centroid_wbm%>%
                      #  dplyr::rename_with(~ paste0(.,"_ws"), -c(date,gcm))
 
```

##### 3.7. USGS Data

For many parks, the nearest USGS stream gage is far away. Therefore, we are 
pulling all NWIS gages within 100 km of the park boundary. Of those, we only 
select stream gages that are considered "reference" gages in the 
[GAGES-II database (Falcone, 2011)](https://pubs.usgs.gov/publication/70046617).
Then, we delineate each of those gages' watersheds using the `get_nldi_basin()` 
function from the {nhdplusTools} package:

```{r, eval = TRUE, message = FALSE, warning = FALSE}

# Get all NWIS sites
nwis <- listNWIS(aoi = watersupply_watershed %>% 
                   dplyr::summarize(), dist = .3) #%>%


  #dplyr::filter(data_type_cd == "dv",
  #       code == "00060")

# Get NWIS Stream Gages
ref_gages <- get_gagesII(id = nwis$site_no) %>%
             dplyr::filter(class == "Ref")

nwis_stream <- nwis %>%
              dplyr::filter(site_no %in% ref_gages$staid,
                            data_type_cd == "dv") %>%
              dplyr::left_join(st_drop_geometry(ref_gages), 
                               by = c("site_no" ="staid")) 

# Download data from reference stream sites
nwis_stream_discharge <- 
  dataRetrieval::readNWISdv(siteNumbers = nwis_stream$site_no,
                            parameterCd = c('00060','00065')) %>%
    dplyr::mutate(y = year(Date), m = month(Date)) %>%
    dplyr::filter(y >= 1980) %>%
    dplyr::group_by(y,m, site_no) %>%
    dplyr::summarize(mean_discharge = mean(X_00060_00003, na.rm. = TRUE),
                     .groups = "keep") %>%
    dplyr::ungroup() %>%
    dplyr::mutate(ym = lubridate::make_date(year = y, month = m, day = 1)) %>% 
    dplyr::select(ym, site_no, mean_discharge) %>%
    tidyr::pivot_wider(names_from = site_no, 
                       names_prefix = "gage_", 
                       values_from = mean_discharge) #%>%

# Download data from reference stream sites
#getNWIS(inventory = nwis_stream, park = "misc", path = "data/")


# Define functions to get those watersheds for ref. gages using get_nldi_basin 
# in from {nhdplusTools}.

# ================ Function to identify NLDI watersheds ========================


# Now, use functions to get watersheds associated with stream gages
nldi_watershed <- 
  nwis_stream$site_no %>%
  purrr::map_dfr(~nldi_finder(site_no = .)) %>%
  dplyr::mutate(data = map(site_no, ~nldi_meta(site_no = .))) %>%
  unnest(cols = c(data)) %>%
  dplyr::left_join(st_drop_geometry(nwis), by = "site_no")

nldi_flowlines <- 
  dplyr::summarize(nldi_watershed) %>%
  mapNHDPlusHR() %>% 
  dplyr::summarize()


# Now Get Gw sites

nwis_groundwater <- nwis %>%
  dplyr::filter(begin_date != end_date,
                n_obs > 50,
                # groundwater sites only:
                site_type_cd == "GW",
                data_type_cd == "gw",
                code == 72019) %>%
  dplyr::mutate(dist = st_distance(geometry,park_boundary) %>%
                as.numeric()) %>%
  dplyr::filter(dist <= 1600*3) %>%
  add_gw_meta()


# pull those sites groundwater level data and convert to monthly mean
  nwis_groundwater_levels <- 
    dataRetrieval::readNWISgwl(nwis_groundwater$site_no) %>%
    dplyr::filter(parameter_cd == 62611,
                  year(lev_dt) >= 1980) %>% # 72019 =Depths, 62611=elevation
    dplyr::mutate(ym = lubridate::ym(substr(lev_dt, 1, 7))) %>% 
    dplyr::group_by(ym, site_no) %>%
    dplyr::summarize(mean_lev_va = mean(sl_lev_va, na.rm. = TRUE), # elevation
                     #mean_lev_va = mean(lev_va, na.rm. = TRUE), # depths
                     .groups = "keep") %>%
    dplyr::select(ym, site_no, mean_lev_va) %>%
    tidyr::pivot_wider(names_from = site_no, names_prefix = "well_", 
                       values_from = mean_lev_va) #%>%


```

#### 3.8. Park Visitation

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
# NPS monthly visitor information
visitors <- 
  getUnitVisitation(units = park, startYear = 1980, endYear = 2023) %>%
  dplyr::mutate(ym = ym(paste0(Year, "-", Month))) %>%
  dplyr::mutate(TotalVisitors = RecreationVisitors + NonRecreationVisitors) %>%
  dplyr::select(ym, RecreationVisitors, TotalVisitors) %>%
  mutate(ifelse(TotalVisitors == 0,NA,TotalVisitors),
         ifelse(RecreationVisitors ==0, NA, RecreationVisitors))


```

#### 3.9. Water use data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get state specific water use data --> in monthly format

if (state == "UT") {

  water_supply_id <- getWaterSuppliersUtah(aoi = park_boundary) %>%
    filter(grepl("National", WRNAME, ignore.case=TRUE) | 
           grepl("National", WRENAME, ignore.case = TRUE)) %>%
    .$WRID

  if (!sum(water_supply_id)==0) {
  
   water_use <- map_dfr(water_supply_id, 
                     \(x) getWaterUseUtah(WRID = x)[[1]] %>%
      dplyr::filter(!is.na(suppressWarnings(as.numeric(Year)))) %>%
      tidyr::pivot_longer(-c("Year","Method of Measurement"), 
                          names_to = "month", 
                          values_to = "use_acre_feet") %>%
      dplyr::filter(month != "Annual inAcre Feet") %>%
      dplyr::mutate(ym = ym(paste0(Year, "-", month))) %>%
      drop_na(ym) %>%
      dplyr::group_by(ym) %>%
      dplyr::summarize(use_acre_feet = sum(as.numeric(use_acre_feet), 
                                           na.rm = TRUE)) %>%
        mutate(WRID=paste0("WRID_",x))) %>%
     pivot_wider(names_from = WRID, values_from = use_acre_feet) %>%
     mutate(use_acre_feet = rowSums(dplyr::select(., !starts_with("ym")), 
                                    na.rm = TRUE))
  
  } else if (water_supply_id == 0 ) {
    water_use = Visitors %>%
      mutate(water_use_gal = TotalVisitors*5)
    }

}
```

### 4. Data Analysis

###### 4.1 Data munging

Before we can analyze all the data we've accumulated, we must aggregate data into daily, monthly, seasonal, and yearly sets. In this section, we join the previously amassed datasets and calculate some general statistics.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Set date range for historic and future aggregation periods
hist_years <- c(1980,2010)      # 30 year
future_years <- c(2040,2070)   # 30 year

# For temporal aggregations, some variables will be summarized using the mean 
# while others will use the sum. Define which cols for subsequent calculations
mean_cols <- c("tavg_f", "tmax_f","tmin_f", "r_hmax_percent", "r_hmin_percent",
               "deficit_in", "soil_water_in", "runoff_in", "accumswe_in")

sum_cols <- c("precip_in", "rain_in", "snow_in","aet_in", "pet_in", 
              "days_gt_92F", "days_lt_32F", "days_gt_95pcp", "days_gt_95roff", 
              "days_gt_77F", "days_lt_05roff", "days_w_pcp","days_w_swe")


################################ Daily Stats ###################################

# First, calculate some generic stats on daily data for historic and future
# periods of interest

# Join centroid data -- daily frequency
centroid_all <- left_join(centroid_climate %>%
                            dplyr::filter(!is.na(cf)), # remove non-selected cfs
                          centroid_wbm %>%
                            dplyr::filter(!is.na(cf)), 
                by = c("date","gcm","cf", "centroid","unit_climate_zone")) %>%
                mutate(snow_in = precip_in - rain_in)

# Calculate some generic stats for all variables using daily data
stats <- centroid_all %>%
  dplyr::mutate(stat_group = 
               dplyr::case_when(year(date) > hist_years[1] & 
                                year(date) < hist_years[2] ~ "Historical",
                                year(date) > future_years[1] & 
                                year(date) < future_years[2] ~ "Future")) %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::select(-c(date, gcm, unit_climate_zone, centroid)) %>%
  dplyr::group_by(cf,stat_group) %>%
  dplyr::summarize_all(.funs = 
                        list(Q95 = ~ quantile(., probs = 0.95, na.rm = TRUE),
                             Q05 = ~ quantile(., probs = 0.05, na.rm = TRUE),
                            mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")


# Now, add binary indicator to get day counts (e.g., 1 for days over X degrees,
# 0 for days under X degrees)
centroid_all <- centroid_all %>%
  group_by(cf) %>%
      # Get day counts for conditional statistics
      dplyr::mutate(days_gt_92F = ifelse(    tmax_f > 92, 1, 0),
                    days_gt_77F = ifelse(    tmax_f > 77, 1, 0),
                    days_lt_32F = ifelse(    tmin_f < 32, 1, 0),
                    days_w_pcp = ifelse(  precip_in >  0, 1, 0),
                    days_w_swe = ifelse(accumswe_in >  0, 1, 0),
                  days_gt_95pcp = ifelse(precip_in >= stats[stats$stat_group == 
                                              "Historical",]$precip_in_Q95,1,0),
                 days_gt_95roff = ifelse(runoff_in >= stats[stats$stat_group == 
                                              "Historical",]$runoff_in_Q95,1,0),
                 days_lt_05roff = ifelse(runoff_in <= stats[stats$stat_group == 
                                              "Historical",]$runoff_in_Q05,1,0))

############################## Seasonal Stats ##################################

# Create Seasonal Dataframe
centroid_seasonal <- centroid_all %>%
  dplyr::mutate(season = case_when(month(date) %in% c(12,1,2) ~ "Winter",
                            month(date) %in% c(3,4,5) ~ "Spring",
                            month(date) %in% c(6,7,8) ~ "Summer",
                            month(date) %in% c(9,10,11) ~ "Fall")) %>%
  dplyr::mutate(y = year(date)) %>%
  dplyr::select(-c(date,gcm)) %>%
  dplyr::group_by(y,season,cf)%>%
  dplyr::summarize(
              across(all_of(sum_cols),sum),  # Sum of columns in sum_cols list
              across(all_of(mean_cols),mean),
              peak_swe_in = max(accumswe_in),
              peak_runoff_in = max(runoff_in),
              .groups = "keep")


seasonal_stats <- centroid_seasonal %>%
  dplyr::mutate(stat_group = 
                  ifelse(y > hist_years[1] & y < hist_years[2], "Historical",
                  ifelse(y > future_years[1] & y < future_years[2], 
                                    "Future",NA))) %>%
  dplyr::ungroup() %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::group_by(cf,stat_group,season) %>%
  dplyr::summarize_all(.funs = 
                        list(mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")
  
############################## Monthly Stats ###################################

# Create Monthly Dataframe
centroid_monthly <- centroid_all  %>%
  # Group and summarize by month and year
            dplyr::mutate(y = year(date), m = month(date)) %>%
            dplyr::select(-c(date)) %>%
            dplyr::group_by(y,m,gcm,unit_climate_zone,cf) %>%
            dplyr::summarize(
              across(all_of(sum_cols),sum),  
              across(all_of(mean_cols),mean),
                     peak_swe_in = max(accumswe_in),
                     peak_runoff_in = max(runoff_in),
              .groups = "keep") %>%
            dplyr::mutate(ym = make_date(y,m), .before = gcm) %>%
            dplyr::ungroup() %>%
            dplyr::select(-c(y,m)) %>%
  # Add other monthly datasets to monthly
            dplyr::left_join(nwis_groundwater_levels, by = c("ym")) %>%
            dplyr::left_join(nwis_stream_discharge, by = c("ym")) %>%
            dplyr::left_join(visitors, by = c("ym")) %>%
            dplyr::left_join(water_use,by = c("ym")) %>%
  # calculate some new values
  mutate(demand_pp_af = use_acre_feet/TotalVisitors,
         demand_pp_gal = 325851 * demand_pp_af,
         use_acre_feet = ifelse(use_acre_feet == 0, NA, use_acre_feet))

  
############################### Annual Stats ###################################

# Define new columns that have been added since monthly dataframe was created
new_cols_sum <- c("use_acre_feet","TotalVisitors","RecreationVisitors")
new_cols_mean <- 
  names(nwis_groundwater_levels)[2:length(names(nwis_groundwater_levels))]

# Create annual Dataframe
centroid_annual <- centroid_monthly  %>%
            dplyr::mutate(y = year(ym)) %>%
            dplyr::select(-c(ym)) %>%
            dplyr::group_by(y,gcm,unit_climate_zone,cf) %>%
            dplyr::summarize(
              across(all_of(sum_cols),sum),  # Sum of columns in sum_cols list
              across(all_of(mean_cols), \(x) mean(x, na.rm = TRUE)),
              across(all_of(new_cols_sum),sum),
              across(all_of(new_cols_mean), \(x) mean(x, na.rm = TRUE)),
              peak_swe_in = max(peak_swe_in),
              peak_runoff_in = max(peak_runoff_in),
              .groups = "keep") %>%
          # recalculate demand with annual data
          mutate(demand_pp_af = use_acre_feet/TotalVisitors,
          demand_pp_gal = 325851 * demand_pp_af,
          use_acre_feet = ifelse(use_acre_feet == 0, NA, use_acre_feet))


#save(list = c("centroid_monthly","centroid_annual","watersupply_watershed","park_boundary"),
#     file = "data/Visitation_Demand_Projections/BRCA_dat.Rdata")


# Create dataframe containing annual statistics for historical and future 
# subsets of data
annual_stats <- centroid_annual %>%
  dplyr::mutate(stat_group = 
                  ifelse(y > hist_years[1] & y < hist_years[2], "Historical",
                  ifelse(y > future_years[1] & y < future_years[2], 
                                    "Future",NA))) %>%
  dplyr::ungroup() %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::select(-c(gcm,unit_climate_zone)) %>%
  dplyr::group_by(cf,stat_group) %>%
  dplyr::summarize_all(.funs = 
                        list(mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")

  
```

###### 4.2 Timing, Frequency. & Duration

Climate change will alter the timing, frequency, and duration of various aspects of the hydrological cycle. Herein, we calculate statistics to track changes in the timing, frequency, and duration of variables of interest.

```{r}

# Create a dataframe containing the number of consecutive years that a variable
#meets various thresholds. 

streaks <- streak_finder(df = centroid_annual, 
                          var = "runoff_in", 
                          q1 = 0.1, 
                          q2 = 0.9)


streaks_summary <- streaks %>% 
  pivot_wider(names_from = stat, values_from = streak_length) %>%
  group_by(cf) %>%
  dplyr::summarize(max_high = max(`High Year Streak`, na.rm = TRUE),
            max_low = max(`Low Year Streak`, na.rm = TRUE),
            count_high = sum(`High Year Streak`, na.rm = TRUE),
            count_low = sum(`Low Year Streak`, na.rm = TRUE),
            .groups = "keep") %>%
  mutate(freq_high = ifelse(cf == "Historical", count_high / (2022-1979),
         count_high / (2099-2026)),
         freq_low = ifelse(cf == "Historical", count_low / (2022-1979),
         count_low / (2099-2026))) %>%
  mutate_all(function(x) ifelse(is.infinite(x), 0, x))

q1 <- 0.1
q2 <- 0.9

historic_probs <- centroid_annual %>%
    dplyr::filter(cf == "Historical") %>%
    dplyr::select(runoff_in) %>%
    ungroup() %>%
    dplyr::summarize(QLOW = quantile(runoff_in, probs = as.numeric(q1)),
                     QHIGH = quantile(runoff_in, probs = as.numeric(q2)))

streak_check <- centroid_annual %>%
  mutate(low_year = ifelse(runoff_in <= historic_probs$QLOW, 1, NA),
         high_year = ifelse(runoff_in >= historic_probs$QHIGH, 1, NA)) %>%
  dplyr::select(y, cf, low_year, high_year, runoff_in)



################################. DOY Stats ####################################

doy <- centroid_all %>%
  mutate(doy = yday(date)) %>%
  dplyr::select(-c(gcm, unit_climate_zone, centroid,date)) %>%
  group_by(cf,doy) %>%
  summarize_all(mean) %>%
  dplyr::select(doy, cf, tavg_f, precip_in, accumswe_in, aet_in, snow_in, rain_in,
                deficit_in, runoff_in) %>%
  pivot_longer(cols = -c(cf,doy), values_to = "vals", names_to = "vars") %>%
  mutate(ym = as.Date(doy, origin = "2014-01-01"),
         name = case_when(vars == "accumswe_in" ~ "SWE (in)",
                          vars == "aet_in" ~ "AET (in)",
                          vars == "deficit_in" ~ "Soil Water Deficit (in)",
                          vars == "precip_in" ~ "Precipitation (in)",
                          vars == "runoff_in" ~ "Runoff (in)",
                          vars == "tavg_f" ~ "Temperature (F)",
                          vars == "snow_in" ~ "Snow (in)",
                          vars == "rain_in" ~ "Rain (in)"))
  

############################## Runoff timing ###################################

# here is a bimodal distribution for the day-of-year for the maximum
# precipitation AND correspondingly runoff. 

# Runoff timing 

# Group by year and select daily maximum discharge with corresponding date
max_annual_runoff <- centroid_all %>%
  mutate(Date = date,
         year = year(date)) %>%
  dplyr::select(c(Date,cf,year,runoff_in)) %>%
  addWaterYear() %>%
  dplyr::group_by(cf,waterYear) %>% 
  dplyr::slice_max(order_by = runoff_in, n=1, with_ties = FALSE) %>%
  mutate(doy = yday(Date),
         dowy = as.numeric(Date - as.Date(paste0(waterYear-1,"-10-01"))),
         season = case_when(month(Date) %in% c(12,1,2) ~ "Winter",
                            month(Date) %in% c(3,4,5) ~ "Spring",
                            month(Date) %in% c(6,7,8) ~ "Summer",
                            month(Date) %in% c(9,10,11) ~ "Fall"))


# calculate slopes, or rate of annual change. Negative indicates earlier runoff
spring_runoff_yearly_change <- max_annual_runoff %>%
  filter(season == "Spring" | season == "Winter") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep") %>%
      mutate(dir = case_when(slope < 0 ~ paste0("shifted earlier on average by ",round(slope,1)," days per year"),
                             slope > 0 ~ paste0("shifted later on average by ",round(slope,1)," days per year"),
                             slope == 0 ~ "does not significantly shift"),
             slope_round = abs(round(slope,1)))

fall_runoff_yearly_change <- max_annual_runoff %>%
  filter(season == "Fall" | season == "Summer") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

################################. Peak SWE timing ##############################
# Group by year and select daily maximum discharge with corresponding date
max_annual_swe <- centroid_all %>%
  mutate(Date = date,
         year = year(date)) %>%
  dplyr::select(c(Date,cf,year,accumswe_in)) %>%
  addWaterYear() %>%
  dplyr::group_by(cf,waterYear) %>% 
  dplyr::slice_max(order_by = accumswe_in, n=1, with_ties = FALSE) %>%
  mutate(doy = yday(Date),
         dowy = as.numeric(Date - as.Date(paste0(waterYear-1,"-10-01"))),
         season = case_when(month(Date) %in% c(12,1,2) ~ "Winter",
                            month(Date) %in% c(3,4,5) ~ "Spring",
                            month(Date) %in% c(6,7,8) ~ "Summer",
                            month(Date) %in% c(9,10,11) ~ "Fall"))


# calculate slopes, or rate of annual change. Negative indicates earlier runoff
spring_swe_yearly_change <- max_annual_swe %>%
  filter(season == "Spring" | season == "Winter") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep") %>%
      mutate(dir = case_when(slope < 0 ~ paste0("shifted earlier on average by ",round(slope,1)," days per year"),
                             slope > 0 ~ paste0("shifted later on average by ",round(slope,1)," days per year"),
                             slope == 0 ~ "no significant shifts"),
             slope_round = abs(round(slope,1)))

fall_swe_yearly_change <- max_annual_swe %>%
  filter(season == "Fall" | season == "Summer") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")



################################# Precip timing ################################

max_annual_precip <- centroid_all %>%
  mutate(Date = date,
         year = year(date)) %>%
  dplyr::select(c(Date,cf,year,precip_in)) %>%
  addWaterYear() %>%
  dplyr::group_by(cf,waterYear) %>% 
  dplyr::slice_max(order_by = precip_in, n=1, with_ties = FALSE) %>%
  mutate(doy = yday(Date),
         dowy = as.numeric(Date - as.Date(paste0(waterYear-1,"-10-01"))),
         season = case_when(month(Date) %in% c(12,1,2) ~ "Winter",
                            month(Date) %in% c(3,4,5) ~ "Spring",
                            month(Date) %in% c(6,7,8) ~ "Summer",
                            month(Date) %in% c(9,10,11) ~ "Fall"))

# calculate slopes, or rate of annual change. Negative indicates earlier precip
spring_precip_yearly_change <- max_annual_precip %>%
  filter(season == "Spring" | season == "Winter") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

fall_precip_yearly_change <- max_annual_precip %>%
  filter(season == "Fall" | season == "Summer") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

```

###### 4.3 Visitation

Visitation is a major driver of park water use. In order to predict future water demands, we must also have a sense of future visitation. In this section, we develop models to predict future visitation and calculate some visitation stats.

Importantly,temperature has been identified as a strong predictor of visitation trends at national parks (Fisichelli et al., 2015). citation: Fisichelli NA, Schuurman GW, Monahan WB, Ziesler PS (2015) Protected Area Tourism in a Changing Climate: Will Visitation at US National Parks Warm Up or Overheat? PLoS ONE 10(6): e0128226. <https://doi.org/10.1371/journal.pone.0128226>

Start by plot monthly visitor proportions to see if park visitor data follow temperature relationships identified by Fisichelli et al., 2015. Currently, we use the mean of max daily temperatures (tmax_F) for each month to calculate proportions, but this was also tested with the average daily temp which produced similar results.

```{r}

# identify regression variables
visitor_regress <- purrr::map(
 # Elements to iterate over
  centroid_monthly %>% 
    dplyr::filter(year(ym) < 2024) %>%
    dplyr::select(-c(ym, gcm, cf, unit_climate_zone,TotalVisitors)),
  ~lm(TotalVisitors ~ .x, data = centroid_monthly %>%
        dplyr::filter(year(ym) < 2024))) %>%
  purrr::map(broom::glance) %>%
  dplyr::bind_rows(.id = "variable") %>%
  dplyr::select(variable, r.squared) %>%
  arrange(.,desc(r.squared))


# First test monthly proportions

monthly_proportion <- centroid_monthly %>%
  mutate(y = year(ym)) %>%
  dplyr::filter(y < 2024) %>%
  group_by(y) %>%
  mutate(vis_sum = sum(TotalVisitors, na.rm = TRUE),
         monthly_vis_prop = TotalVisitors/vis_sum,
         dem_sum = sum(use_acre_feet, na.rm = TRUE),
         monthly_dem_prop = use_acre_feet/dem_sum,
         tmax_c = (tmax_f - 32)*5/9) 

a <- ggplot(monthly_proportion) + 
  geom_boxplot(aes(x = floor(tmax_c), 
                   y = monthly_vis_prop, 
                   group = floor(tmax_c))) + 
  labs(x = "Monthly Temperature (C)", 
       y = "Monthly visitation (proportion)",
       title = park_name)

b <- ggplot(monthly_proportion) + 
  geom_boxplot(aes(x = floor(tmax_c), 
                   y = monthly_dem_prop, 
                   group = floor(tmax_c))) + 
  labs(x = "Monthly Temperature (C)", 
       y = "Monthly water demand (proportion)",
       title = park_name)

ggarrange(a,b,nrow = 1)


# At BRCA -- monthly visitation does not appear to decrease over 77 degrees F,
# as predicted by Fisichelli. So....

# Develop a multiple linear regression model that uses mean monthly temperature, 
# the number of days per month with temperatures greater than 77F, and the year 
# to predict # monthly park visitors.

# Function to create a population curve from the year. The "2000" can be 
# modified to change where the population curve peaks. May want to explore more
pop_curve <- function(year, k = 0.1, L = 20) {
  ymean <- mean(year, na.rm = TRUE)
  pop <- (L / (1 + exp(-k * (year - 1985)))) + 1
}



# Add new variabls to df
centroid_monthly <- centroid_monthly %>%
                   mutate(TotalVisitorsLog = log(TotalVisitors),
                          y = year(ym), 
                          m = month(ym),
                          pop = pop_curve(y)) 

plot(centroid_monthly$ym, centroid_monthly$pop)

# Develop model
visitor_mlr = lm(formula = TotalVisitorsLog ~ 
                    tavg_f +
                    days_gt_77F +
                    days_lt_32F +
                    #days_w_swe +
                    pop,
                   data = centroid_monthly %>%
                   filter(year(ym) <= 2023))

print(summary(visitor_mlr))


# Add projections to monthly dataframe
centroid_monthly <- 
  mutate(centroid_monthly,
            TotalVisitors_mlr_fit = exp(predict(visitor_mlr, centroid_monthly)),
            TotalVisitors_mlr_lwr = exp(predict(visitor_mlr, centroid_monthly, 
                                            interval = "confidence")[,2]),
            TotalVisitors_mlr_upr = exp(predict(visitor_mlr, centroid_monthly, 
                                            interval = "confidence")[,3]),
         TotalVisitors_all = case_when(year(ym) < 2024 ~ TotalVisitors,
                                       year(ym) >= 2024 ~ TotalVisitors_mlr_fit),
         TotalVisitorsLog = log(TotalVisitors_all))



if ("TotalVisitors_mlr_fit" %in% names(centroid_annual)) {
          centroid_annual <- centroid_annual %>%
          dplyr::select(-c(TotalVisitors_mlr_fit,TotalVisitors_mlr_lwr,TotalVisitors_mlr_upr))
 }

# Sum and add to annual dataset
centroid_annual <- centroid_monthly %>%
  dplyr::select(-c(ym,gcm,unit_climate_zone)) %>%
  group_by(y,cf) %>%
  dplyr::summarize(TotalVisitors_mlr_fit = sum(TotalVisitors_mlr_fit, na.rm = FALSE),
            TotalVisitors_mlr_lwr = sum(TotalVisitors_mlr_lwr, na.rm = FALSE),
            TotalVisitors_mlr_upr = sum(TotalVisitors_mlr_upr, na.rm = FALSE),
            .groups = "keep") %>%
  left_join(., centroid_annual, by = c("y","cf")) %>%
  mutate(TotalVisitors_all = case_when(y < 2024 ~ TotalVisitors,
                                       y >= 2024 ~ TotalVisitors_mlr_fit),
         TotalVisitors_log = log(TotalVisitors_all))

# Plot monthly visitors
ggplot(centroid_monthly %>% filter(year(ym) < 2070)) + 
  geom_line(aes(x = ym, 
                y = TotalVisitors_mlr_fit, 
                color = cf), 
            size = 1) +
  geom_ribbon(aes(x = ym, 
                  ymin = TotalVisitors_mlr_lwr, 
                  ymax = TotalVisitors_mlr_upr),
              alpha = 0.3,
              fill = "hotpink") +
  geom_line(aes(x = ym, 
                y = TotalVisitors,color = "historical_actual"), 
            size = 1) + 
  scale_color_manual("",
                     values = c("hotpink","black","red","cornflowerblue"), 
                     labels = c("MLR Model","Historical","Hot Dry", "Warm Wet" )) + 
  labs(x = "", y = "Total Monthly Visitors", title = "BRCA") + 
  theme_bw() #+ coord_trans(y = "log10") 

#ggsave('data/Test_Figures/Visitors_Proj_Model.jpg', width = 8, height = 4, units = c("in"),
 #      dpi = 600)

annual_visitor_summary <- centroid_annual %>%
  dplyr::select(y,cf,TotalVisitors_all) %>%
  dplyr::filter(y >= 2000) %>%
  group_by(cf) %>%
  drop_na(TotalVisitors_all) %>%
  dplyr::summarize(sens_slope = trend::sens.slope(TotalVisitors_all)$estimates[1],
                   pval = trend::sens.slope(TotalVisitors_all)$p.value,
                   mean = mean(TotalVisitors_all),
                   percent_chg = 100*trend::sens.slope(TotalVisitors_all)$estimates[1] / mean(TotalVisitors_all)) %>%
  mutate(text = case_when(sens_slope < 0 & pval < 0.05 ~ paste0("decreased on average by ",round(percent_chg,1)," % per year"),
                          sens_slope > 0 & pval < 0.05 ~ paste0("increased on average by ",round(percent_chg,1)," % per year"),
                          sens_slope == 0 | pval > 0.05 ~ "not significantly changed"))

```

###### 4.4 Water Demand

Next, we'll use visitation projections to make estimates about future demands. Again, we'll develop models to predict future water demands using historical data and then we'll project models into the future.

```{r demand_per_person_plots, warning = FALSE, echo = FALSE, fig.width =5}

# Start by looking at general trends in use and per person demand

a <- ggplot(centroid_monthly %>% filter(year(ym) < 2024),
            aes(x = ym, y = demand_pp_gal)) + 
  geom_point(color = "dodgerblue") +
  geom_smooth(color = "dodgerblue4",fill = "dodgerblue4") + 
  labs(y = "Monthly", x = "", 
       title = "      Water Use (gallons per person)") +
  theme_bw()

b <- ggplot(centroid_annual %>% filter(y < 2024), 
            aes(x = y, y = demand_pp_gal)) + 
  geom_point(color = "dodgerblue") + 
  geom_smooth(color = "dodgerblue4",fill = "dodgerblue", span = 1) + 
  labs(y = "Annual", x = "") +
  theme_bw()

ggarrange(a,b, nrow = 2)

```

Next, Develop models to predict future water demand .

```{r }

# First create calibrated model with historic data then project.

# identify regression variables
use_regress <- purrr::map(
 # Elements to iterate over
  centroid_monthly %>% 
    dplyr::filter(y < 2024) %>%
    dplyr::select(-c(ym, gcm, cf, unit_climate_zone,use_acre_feet)),
  ~lm(use_acre_feet ~ .x, data = centroid_monthly %>%
        dplyr::filter(y < 2024))) %>%
  purrr::map(broom::glance) %>%
  dplyr::bind_rows(.id = "variable") %>%
  dplyr::select(variable, r.squared) %>%
  arrange(.,desc(r.squared))


# Next try multiple linear regression which uses multiple inputs
demand_mlr_model = lm(formula = use_acre_feet ~ 
                    tmax_f +
                    days_lt_32F +
                   TotalVisitorsLog +
                     pet_in,
                 data = centroid_monthly %>%
                              filter(year(ym) < 2023) %>%
                              mutate(use_acre_feet = 
                                ifelse(use_acre_feet == 0, NA, use_acre_feet)))

print(summary(demand_mlr_model))

centroid_monthly <- 
  mutate(centroid_monthly,
            MLR_demand_fit = predict(demand_mlr_model, centroid_monthly),
            MLR_demand_lwr = predict(demand_mlr_model, centroid_monthly, interval = "confidence")[,2],
            MLR_demand_upr = predict(demand_mlr_model, centroid_monthly, interval = "confidence")[,3],
         demand_all = case_when(year(ym) < 2024 ~ use_acre_feet,
                                year(ym) > 2024 ~ MLR_demand_fit))


# How does it do for annual predictions
demand_annual <- centroid_monthly %>%
  dplyr::select(c('y','use_acre_feet','MLR_demand_fit','cf')) %>%
  group_by(y,cf) %>%
  summarize_all(list(sum))

r_squared <- cor(na.omit(demand_annual) %>% pull(use_acre_feet), 
                 na.omit(demand_annual) %>% pull(MLR_demand_fit))^2

# What if instead you calibrate the model to annual data

# identify regression variables
use_regress_annual <- purrr::map(
 # Elements to iterate over
  centroid_annual %>% 
    ungroup() %>%
    dplyr::filter(y < 2024) %>%
    dplyr::select(-c(gcm, cf, unit_climate_zone, use_acre_feet)),
  ~lm(use_acre_feet ~ .x, data = centroid_annual %>%
        dplyr::filter(y < 2024))) %>%
  purrr::map(broom::glance) %>%
  dplyr::bind_rows(.id = "variable") %>%
  dplyr::select(variable, r.squared) %>%
  arrange(.,desc(r.squared))


# multiple linear regression
demand_mlr_modelA = lm(formula = use_acre_feet ~ 
                    tavg_f +
                    days_gt_95roff + 
                    TotalVisitors_all+
                     aet_in +
                     snow_in,
                 data = centroid_annual %>%
                        filter(y < 2023) %>%
                        mutate(use_acre_feet = 
                            ifelse(use_acre_feet == 0, NA, use_acre_feet)))

summary(demand_mlr_modelA)

centroid_annual <- centroid_annual %>%
  mutate(MLR_demandA_fit = predict(demand_mlr_modelA, newdata = centroid_annual),
         MLR_demandA_lwr = predict(demand_mlr_modelA, newdata = centroid_annual, interval = "confidence")[,2],
         MLR_demandA_upr = predict(demand_mlr_modelA, newdata = centroid_annual, interval = "confidence")[,3],
         demand_all = case_when(y < 2024 ~ use_acre_feet,
                                y > 2024 ~ MLR_demandA_fit))


# Plot both models for yearly values

# Doesn't do great for annual water use -- so develop separate annual model
a <- ggplot(demand_annual %>% 
         filter(y < 2025) %>%
         mutate(use_acre_feet = ifelse(use_acre_feet == 0, NA, use_acre_feet)) %>%
         drop_na(use_acre_feet) %>%
         pivot_longer(cols = -c(y,cf), names_to = 'vars', values_to = 'vals'),
         aes(x = y, y = vals, color = vars)) + 
  geom_line(size = 1) + 
  scale_color_manual("", values = c("hotpink","black"),
                         labels = c("MLR Model","Actual")) + 
  labs(x = "", y = "Annual Water Use (af)", title = "Monthly Model") +
  theme_bw()

b <- ggplot(centroid_annual  %>% 
         filter(y < 2025) %>%
         mutate(use_acre_feet = ifelse(use_acre_feet == 0, NA, use_acre_feet)) %>%
         drop_na(use_acre_feet)) + 
  geom_line(aes(x = y, y = use_acre_feet,
             color = "Actual Use"), size = 1) +
geom_line(aes(x = y, 
              y = MLR_demandA_fit,
             color = "MLR Model"), size = 1) +
  scale_color_manual("", values = c("black","hotpink")) +
  labs(x = "", y = "Annual Water Use", title = "Annual Model") + theme_bw() 

ggarrange(a,b,nrow = 2)

ggsave('data/Test_Figures/Demand_Historic_Annual.jpg', width = 8, height = 4, units = c("in"),
       dpi = 600)


# Plot projections
ggplot(centroid_annual %>%
         mutate(use_acre_feet = ifelse(use_acre_feet == 0, NA,
                                       use_acre_feet))) +
  geom_line(aes(x = y, y = MLR_demandA_fit, color = cf)) +
  geom_ribbon(aes(x = y, ymin =  MLR_demandA_lwr, ymax =  MLR_demandA_upr, 
              color = cf, fill = cf), alpha = 0.2, linewidth = 0) + 
  geom_line(aes(x = y, 
                y = use_acre_feet),
                color = "black") + 
  scale_color_manual("Modeled", values = c("hotpink","red","dodgerblue4")) +
  scale_fill_manual("Modeled", values = c("hotpink","red","dodgerblue4")) +
  labs(x = "", y = "Annual Water Demand (af)") + 
  xlim(1980,2080) + ylim(-100,350) + theme_bw()

#ggsave('data/Test_Figures/Demand_Projected_Model_Annual_model.jpg', width = 8, height = 4, units = c("in"),
#       dpi = 600)

# Plot Monthly

ggplot(centroid_monthly) +
  geom_line(data = centroid_monthly,aes(x = ym, y = MLR_demand_fit, color = cf)) +
  geom_ribbon(data = centroid_monthly,aes(x = ym, ymin =  MLR_demand_lwr, ymax =  MLR_demand_upr, 
              fill = cf), alpha = 0.6, linewidth = 0) + 
  geom_line(data = centroid_monthly %>% filter(year(ym)<2023),
            aes(x = ym, 
                y = use_acre_feet, 
                color = gcm)) + 
  scale_color_manual("", values = c("black","hotpink","red","dodgerblue4")) +
  scale_fill_manual("",values = c("hotpink","red","dodgerblue4")) +
  labs(x = "", y = "Monthly Water Demand (af)") + 
  theme_bw() #+ scale_y_log10() 

#ggsave('data/Test_Figures/Demand_Projected_Model_Monthly_model.jpg', width = 8, height = 4, units = c("in"),
 #      dpi = 600)


# Calculate stats for monthly per person demand for years 2000-2023. Note,
# historic data only
monthly_pp_demand <- centroid_monthly %>%
  dplyr::filter(year(ym) > 2000) %>%
  drop_na(demand_pp_gal) %>%
  mutate(use_gal = use_acre_feet * 325851) %>%
  dplyr::summarize(sens_slope = trend::sens.slope(demand_pp_gal)$estimates[1],
                   pval = trend::sens.slope(demand_pp_gal)$p.value,
                   mean = mean(demand_pp_gal)) %>%
  mutate(percent_chg = 100 * sens_slope / mean,
    text = case_when(sens_slope < 0 & pval < 0.05 ~ paste0("reduced on average by ",round(percent_chg,1),"% per-person per-year.  These reductions likely reflect successful conservation efforts."),
                          sens_slope > 0 & pval < 0.05 ~ paste0("increased on average by ",round(percent_chg,1)," % per year.  These increases may indicate a need to fortify conservation efforts and focus on inefficiencies in the system."),
                          sens_slope == 0 | pval > 0.05 ~ "did not significantly change."))

# Calculate stats summary for annual water use / demand. For historic, only use
# years 2000-2023 to avoid non-linear trends from too far back.
annual_use_summary <- centroid_annual %>%
  dplyr::select(y,cf,demand_all) %>%
  #dplyr::filter(y >= 2000) %>%
  mutate(demand_gal = demand_all * 325851) %>%
  group_by(cf) %>%
  drop_na(demand_all) %>%
  dplyr::summarize(sens_slope = trend::sens.slope(demand_gal)$estimates[1],
                   pval = trend::sens.slope(demand_gal)$p.value,
                   mean = mean(demand_gal)) %>%
  mutate(percent_chg = 100 * sens_slope / mean,
    text = case_when(sens_slope < 0 & pval < 0.05 ~ paste0("decreased on average by ",round(percent_chg,1)," % per year"),
                          sens_slope > 0 & pval < 0.05 ~ paste0("increased on average by ",round(percent_chg,1)," % per year"),
                          sens_slope == 0 | pval > 0.05 ~ "though the long term trend was neither increasing nor decreasing."))

```

Now calculate vulnerability.

```{r}
# Notes
### ADD frequency counts
### ADD black swan events

# water vulnerability is an imbalance between the supply and demand of water 
# resources within a region over a certain time.

# watershed area + conversion factors 
ws_a_c <- 1550*as.numeric(watersupply_watershed_area) * 1.32852e-8

# vulnerability = watersupply_watershed_area * runoff / demand
centroid_annual <- centroid_annual %>%
  mutate(S_D_ratio = 
           case_when(y <= 2023 ~ ws_a_c * runoff_in / use_acre_feet, 
                     y > 2023 ~ ws_a_c * runoff_in / MLR_demandA_fit),
         S_D_ratio_lwr = case_when(y <= 2023 ~ NA,
                                   y > 2023 ~  ws_a_c * runoff_in / MLR_demandA_lwr),
         S_D_ratio_upr = case_when(y <= 2023 ~ NA,
                                   y > 2023 ~ ws_a_c * runoff_in / MLR_demandA_upr))


# Calculate annual trends in the SD Ratio
annual_SD_summary <- centroid_annual %>%
  dplyr::select(y,cf,S_D_ratio) %>%
  dplyr::filter(y >= 2000) %>%
  group_by(cf) %>%
  drop_na(S_D_ratio) %>%
  dplyr::summarize(sens_slope = trend::sens.slope(S_D_ratio)$estimates[1],
                   pval = trend::sens.slope(S_D_ratio)$p.value,
                   mean = mean(S_D_ratio)) %>%
  mutate(text = case_when(sens_slope < 0 & pval < 0.05 ~ paste0("decreasing at a rate of ", round(sens_slope,5), " units per year"),
                          sens_slope > 0 & pval < 0.05 ~ paste0("increasing at a rate of ", round(sens_slope,5), " units per year"),
                          sens_slope == 0 | pval > 0.05 ~ "not significantly changing"),
         percent_chg = 100*sens_slope/mean)


centroid_monthly <- centroid_monthly %>%
  mutate(S_D_ratio = 
           case_when(year(ym) <= 2023 ~ ws_a_c * runoff_in / use_acre_feet, 
                     year(ym) > 2023 ~ ws_a_c * runoff_in / MLR_demand_fit),
         S_D_ratio_lwr = 
           case_when(year(ym) <= 2023 ~ NA,
                     year(ym) > 2023 ~ ws_a_c * runoff_in / MLR_demand_lwr),
         S_D_ratio_upr = 
           case_when(year(ym) <= 2023 ~ NA,
                     year(ym) > 2023 ~ ws_a_c * runoff_in / MLR_demand_upr))
         
# Plot monthly
ggplot(centroid_monthly,
       aes(x = ym, y = S_D_ratio, color = cf, fill = cf)) + 
  geom_point() + 
  geom_smooth() + 
  scale_color_manual("", values = c("darkgray","red","dodgerblue")) +
  scale_fill_manual("", values = c("darkgray","red","dodgerblue")) +
  ylim(0,100) +
  theme_bw() +
  labs(x = "", y = "Monthly S-D Ratio")
#ggsave('data/Test_Figures/S-D_Ratio_Monthly.jpg', width = 8, height = 2, units = c("in"),
#       dpi = 600)

ggplot(centroid_annual) +
  #geom_line(aes(x = y, y = S_D_ratio, color = cf),size = 1) +
  geom_point(aes(x = y, y = S_D_ratio, color = cf)) +
  geom_ribbon(aes(x = y, ymin =  S_D_ratio_lwr, ymax =  S_D_ratio_upr, 
              color = cf, fill = cf), alpha = 0.2, linewidth = 0) + 
  geom_smooth(aes(x = y, y = S_D_ratio, color = cf), method = "lm") +
  scale_color_manual("", values = c("darkgray","red","dodgerblue")) +
  scale_fill_manual("", values = c("darkgray","red","dodgerblue")) +
  labs(x = "", y = "Annual S-D Ratio") + 
   ylim(0,1) + theme_bw()
#ggsave('data/Test_Figures/S-D_Ratio_Annual.jpg', width = 8, height = 2, units = c("in"),
#       dpi = 600)

```

###### 4.5 Magnitude Stats

The magnitude of annual change is an important indicator of trends at parks. This section calculates the Sen's slope for each variable with associated metrics for whether this trend is significant.

```{r}

# magnitude df containing the magnitude and direction of change through time for
# each variable as Sen's slope. Note, slope represents degrees farenheit change
# per year for temperature variables, change in days per year for day-count 
# variables, and change gallons per year for water balance terms. Because
# WBM variables are input as length per time (inches-per-year in this case),
# L/T is converted to volume-per-time as gallons per year by multiplying the
# inches-per-time value by the area of the watersupply watershed and a convers-
# ion factor (1550 (in2 per m2) * 0.004329 (in3 per gallon)).

#  Watershed area in gallons / in (for conversion after)
 wsg<- as.numeric(watersupply_watershed_area) * 1550 * 0.004329

magnitude <- centroid_annual %>%
  ungroup() %>%
  dplyr::select(-c(unit_climate_zone, gcm)) %>%
  # Define specific columns to calculate magnitude
  dplyr::select(y, cf, precip_in, rain_in, aet_in, pet_in, days_gt_92F, 
                days_lt_32F, days_gt_95pcp, days_gt_95roff, days_gt_77F,
                days_lt_05roff, days_w_pcp, days_w_swe, tavg_f, tmax_f,
                tmin_f, r_hmax_percent, r_hmin_percent, deficit_in, 
                soil_water_in, runoff_in, accumswe_in, snow_in, peak_swe_in,
                peak_runoff_in, TotalVisitors_all, demand_all, S_D_ratio) %>%
  pivot_longer(cols = -c(y,cf),names_to = "vars", values_to = "vals") %>%
  group_by(cf,vars) %>%
  # For linear method slope, uncomment:
  #dplyr::summarize(slope = round(coef(lm(vals ~ y))[2],3), 
  #.groups = "keep") %>%
  dplyr::summarize(slope = trend::sens.slope(vals[!is.na(vals)])$estimates,
                   pval = trend::sens.slope(vals[!is.na(vals)])$p.value,
                   .groups = "keep") %>%
  mutate(dir = case_when(slope < 0 & pval < 0.05 ~"decreases",
                         slope > 0 & pval < 0.05 ~"increases",
                         slope == 0 | pval >= 0.05  ~ "no significant changes"),
         slope = case_when(pval < 0.05 ~ slope,
                           pval >= 0.05 ~ 0))


# Create dataframe containing the percentage change that occurs from historic 
# to future time periods

annual_percent_change <- (100*(annual_stats[2:3,3:ncol(annual_stats)] -           
                       annual_stats[rep(1,2),3:ncol(annual_stats)]) / 
                       annual_stats[rep(1,2),3:ncol(annual_stats)]) %>%
                      cbind(annual_stats[2:3,1:2],.)

```


30 Year Change Maps

```{r}

# calculate change rasters (%) for runoff
runoff_change_rasters <- map2(rep(scen, 2), c(rep("2040_2069", 2), rep("2070_2099", 2)), function(x, y) {
  (wbm_30y[[grepl(pattern = paste(select_cfs[select_cfs$CF == x, GCM], "runoff", y, sep = "_"),
                  x = names(wbm_30y))]] - wbm_30y[[grepl(
                    pattern = paste("gridmet_historical", "runoff", "1981_2010", sep = "_"),
                    x = names(wbm_30y)
                  )]]) / wbm_30y[[grepl(
                    pattern = paste("gridmet_historical", "runoff", "1981_2010", sep = "_"),
                    x = names(wbm_30y)
                  )]] * 100
}) %>% terra::rast() %>% 
  crop(st_buffer(st_transform(park_boundary, crs(.)), 10000))

# create palette, this is how you would control all maps to be on the same max/min scale
# runoff_change_palette <- c(
#   colorRampPalette(colors = c("darkred", "darkgray"), space = "Lab")(abs(min(
#     values(runoff_change_rasters), na.rm = TRUE
#   ))),
#   colorRampPalette(
#     colors = c("darkgray", "dodgerblue"),
#     space = "Lab"
#   )(max(values(runoff_change_rasters), na.rm = TRUE))
# )


# create all figures
runoff_change_maps <- map(scen, function(x) {
  # map2(rep(scen, 2), c(rep("2040_2069", 2), 
  #                                          rep("2070_2099", 2)), function(x, y) {
  tm_shape(runoff_change_rasters[[grepl(
    pattern = paste(select_cfs[select_cfs$CF == x, GCM], "runoff", "2040_2069", sep = "_"),
    x = names(runoff_change_rasters)
  )]]) +
    tm_raster(
      style = "cont",
      # breaks = c(-1000, -100, 0, 100, 1000),
      # palette = c("red","red", "white", "dodgerblue","dodgerblue"),
      breaks = c(-100, -50, 0, 50, 100),
      palette = c("red", "white", "dodgerblue"),
      midpoint = 0,
      legend.reverse = TRUE,
      n = 6,
      legend.hist = TRUE,
      title = "",#paste0("Predicted Change in\nRunoff: ", y),
      legend.format = list(
        fun = function(z) {
          ifelse(z < -100, "", 
                 ifelse(z > 100, "", 
                        ifelse(z == -100, "â¤ -100 %", 
                               ifelse(z == 100, "â¥ 100 %",
                                      paste0(formatC(
                                        z, digits = 0, format = "f"
                                      ), " %")))))
          
        }
        
      )) +
    tm_shape(park_boundary) +
    tm_borders(col = "black", lwd = 2) +
    tm_shape(st_union(watersupply_watershed)) +
    tm_borders(col = "gold1", lwd = 3) +
    tm_scale_bar(position = c("center", "bottom"), lwd = 2, text.size = 1) +
    tm_add_legend("fill",
                  col = "gold1",
                  labels = "Water Supply Watershed")+
    tm_layout(
      title = paste0("Î Runoff, ", x, "\n2040-2070"),
      title.size = 0.9,
      frame = FALSE,
      legend.outside = TRUE,
      legend.outside.size = 0.35,
      outer.margins = c(0.001, 0.001, 0.001, 0.001),  # Reduce outer margins
      inner.margins = c(0.001, 0.001, 0.001, 0.001),
      legend.position = c("left", "center"),  # Position legend to avoid title overlap
      #legend.outside.position = "bottom" # Reduce inner margins
      
    )
})

tm <- tmap_arrange(runoff_change_maps, ncol = 2, outer.margins = -0.003)

print(tm)
#tmap_save(tm = tm, 
#        filename = "data/Test_Figures/30yr_maps.jpg",  # Replace with your desired filename and extension
#        width = 10,  # Width in inches
#        height = 4,   # Height in inches
#        units = "in",  # Units for width and height
#        dpi = 600)    # Dots per inch (resolution)

```

```{r grammar_section, echo = FALSE}
# add to this later

```

Save data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# save_variables <- c("park_name", "report_name", "runoff_magnitude", 
#                     "spring_runoff_yearly_change", "park_boundary",
#                     "centroid_annual", "centroid_monthly",
#                     "visitor_2013_2023_change", "visitor_2043_2053_change")


## path to data folder (from project directory)
out_path <- paste0("data/park/",park,"/",park,"_report_data.RData")

# save(list = save_variables, 
#      file = out_path)

# for now, just saving everything created in this document while deciding what to use in the report
save.image(out_path)


```

### 5. Examples

1.  Example maps

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
# Optional view data

mapviewOptions(basemaps = c("Esri.WorldStreetMap", "Esri.WorldImagery","Esri.WorldShadedRelief"))

pal = colorRampPalette(c("dodgerblue4","dodgerblue", "white","pink","red"))

#mapview(koppen_park,
#        zcol = "K_vals",
#        #aes(color = color),
#        col.regions = koppen_park$color %>% unique(),
#        #at = koppen_park$K_vals %>% unique(),
#        alpha = 0,
#        homebutton = FALSE,
#        layer.name = "Koppen") +
  mapview(park_boundary, 
        col.regions = "#74a089", 
        alpha.regions = .5, 
        lwd = 2, 
        #popup = FALSE, 
        #legend = F, 
        homebutton = FALSE,
        layer.name = paste0(park," Park Boundary")) +
  mapview(park_watershed,
          col.regions= NA, 
          alpha.regions = 0, 
          lwd = .25, 
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(park_flowlines,
          col.regions = "darkblue",
          lwd = 0.5,
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  # UNCOMMENT IF AVAILABLE
  mapview(dplyr::summarize(watersupply_watershed),
          col.regions = "#E69F00", 
          alpha.regions = .5, 
          #popup = FALSE, 
          #legend = F, 
          homebutton = FALSE,
          layer.name = "Water Supply Watershed",
          legend = FALSE) +
  mapview(watersupply_flowlines,
          col.regions = "darkblue",
          lwd = 0.5,
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
    mapview(nwis_groundwater,
            cex = 6,
            col.regions = c("#8C86A0"),
            label = FALSE,
            homebutton = FALSE,
            layer.name = "NWIS Wells") +
  mapview(nldi_watershed,
          col.regions= NA, 
          alpha.regions = 0, 
          lwd = .5,
          color = "#C0532B",
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(POD_supply,
          col.regions = c("#E69F00"), # orange
          alpha.regions = 1,
          alpha = 1,
          cex = 6, 
          layer.name = "Park Water Supply & Watershed",
          homebutton = FALSE,
          label = FALSE) +
  mapview(nwis_stream,
            cex = 6,
            col.regions = c("#C0532B"),
            homebutton = FALSE,
            layer.name = "NWIS Stream Gages & watersheds") + 
#mapview(st_as_stars(warm_wet_diff_30y),
#        alpha.regions = 0.5,
#        col.regions = pal(20), 
#        at = seq(-1,1,.1),
#        na.color = NA,
#        layer.name = "Runoff Change") + 
  mapview(park_boundary,
          alpha.regions = 0,
          color = "black",
          lwd = 3,
          trim = TRUE)


  #mapview(koppen_cent,
  #        layer.name = "Centroids")

color_list = c("#882314", "#C0532B", "#CF932C", "#674D53", "#8C86A0", "#724438",
               "#D5AB85","#01353D", "#088096", "#58B3C7", "#7AD4E4", "#B8FCFC",
               "#293633", "#3D5051", "#6B7F7F", "#87A1C7", "#516B95", "#304F7D",
               "#0067A2", "#DFCB91", "#CB7223", "#289A84", "#7FA4C2", "#AF7E56")

```

2.  Example Tables

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# kable tips:
# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html


kable(magnitude %>%
     mutate(vars = gsub("_in$", "",vars) %>%
            sapply(., function(x) {
              paste0(toupper(substr(x, 1, 1)), substr(x, 2, nchar(x)), sep = " ")
              })) %>%
       mutate(vars = gsub("_", " ", vars)) %>%
       mutate(vars = gsub("gt",">",vars)) %>%
       mutate(vars = gsub("lt","<",vars)) %>%
        group_by(vars) %>%
        dplyr::select(cf,"Variable" = vars,slope) %>%
        pivot_wider(names_from = cf, values_from = c(slope)), escape = FALSE, booktabs = T,
     digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
kableExtra::landscape() %>%
  #kable_styling(full_width = F) %>%
    kable_paper(full_width = F)
```

```{r wbm_mini_table, echo = FALSE, warning = FALSE}

kable(annual_stats %>%
        #mutate(runoff_in_mean = runoff_in_mean * wsg / 1000) %>%
        pivot_longer(cols = c("snow_in_mean","precip_in_mean","runoff_in_mean","aet_in_mean"), 
                     names_to = "vars", 
                     values_to = "vals") %>%
        dplyr::filter(vars %in% c("snow_in_mean","precip_in_mean","runoff_in_mean","aet_in_mean")) %>%
       mutate(vars = gsub("_in_mean", " (in) ", vars),
              vars = str_to_title(vars)) %>%
        group_by(vars) %>%
        dplyr::select(cf,"Variable" = vars,vals) %>%
        pivot_wider(names_from = cf, values_from = c(vals)), 
     escape = FALSE,
     digits = 1) #%>%
  #kable_styling(table.style = "General_table")

```

3.  Example Timeseries

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

ggplot(centroid_annual %>% filter(y < 2071),
       aes(x = y, y = runoff_in * 0.0254 * as.numeric(st_area(park_boundary)) * 0.000810714, 
           color = as.factor(cf))) + 
   #geom_violin() + 
  geom_boxplot(width = 1) +
  #geom_point() +
  #geom_line()+
  #geom_smooth(aes(fill = as.factor(cf)),span = 3) +
   labs(x = "year", y = "Annual Runoff (acre-feet)") + 
  scale_color_manual("",values = c("gray40","darkred","cornflowerblue")) +
  scale_fill_manual("",values = c("gray40","darkred","cornflowerblue"))
  #facet_wrap(~season, scales = "free")



```

DOY Plots

```{r}
ggplot(doy %>%
         filter(vars %in% c("tavg_f","aet_in", "precip_in", "accumswe_in")), 
       aes(x = ym, y = vals, color = cf)) + 
  geom_line(size = 0.5) + 
  geom_smooth(span = .2, size = 1, se = FALSE) +
  scale_x_date(date_breaks = "2 month", date_labels =  "%b")  + 
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~ factor(name, levels = c('Temperature (F)', 'Precipitation (in)', 
                                      'SWE (in)', 'AET (in)')), 
             scales = "free", ncol = 2) +
  labs(x = "", y = "Value") +
  scale_color_manual("",values = c("darkgray","red","dodgerblue"))

ggsave('data/Test_Figures/DOY_plots.jpg', width = 6, height = 5, units = c("in"),
       dpi = 600)

```

```{r}

ggplot(centroid_annual %>% ungroup() %>%
         dplyr::select(y, cf, tavg_f, precip_in, accumswe_in,aet_in,deficit_in,runoff_in) %>%
         pivot_longer(cols = -c(cf,y), values_to = "vals", names_to = "vars") %>%
         mutate(name = case_when(vars == "accumswe_in" ~ "SWE (in)",
                          vars == "aet_in" ~ "AET (in)",
                          vars == "deficit_in" ~ "Soil Water Deficit (in)",
                          vars == "precip_in" ~ "Precipitation (in)",
                          vars == "runoff_in" ~ "Runoff (in)",
                          vars == "tavg_f" ~ "Temperature (F)")), 
       aes(x = y, y = vals, color = cf)) + 
  geom_line(size = 0.5) + 
  geom_smooth(span = .2, size = 1, se = FALSE) +
  theme_bw() +
  facet_wrap(~ factor(name, levels = c('Temperature (F)', 'Precipitation (in)', 
                                      'Runoff (in)', 'SWE (in)', 'AET (in)', 
                                      'Soil Water Deficit (in)')), 
             scales = "free", ncol = 2) +
  labs(x = "", y = "Value") +
  scale_color_manual("",values = c("darkgray","red","dodgerblue"))

ggsave('data/Test_Figures/timeseries_plots.jpg', width = 14, height = 8, units = c("in"),
       dpi = 600)

```

Trends in the date of maximum runoff

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
a <- ggplot(max_annual_runoff %>% filter(season == "Spring" | season == "Winter"),
       aes(x = year(Date), y = doy, color = cf)) + 
  geom_point() +
  geom_smooth(method = lm) + 
  labs(x = "", y = "Day of maximum annual spring runoff") + 
  scale_color_manual("",values = c("black","darkred","dodgerblue"))

b <- ggplot(max_annual_runoff %>% filter(season == "Summer" | season == "Fall"),
       aes(x = year(Date), y = doy, color = cf)) + 
  geom_point() +
  geom_smooth(method = lm) + 
  labs(x = "", y = "Day of maximum annual spring runoff") + 
  scale_color_manual("",values = c("black","darkred","dodgerblue"))

ggarrange(a,b,ncol = 1)
```

Histograms of the day-of-year of maximum annual runoff

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
ggplot(max_annual_runoff,aes(x = doy, fill = cf)) + geom_histogram() +
  scale_fill_manual("",values = c("black","darkred","dodgerblue")) +
  facet_wrap(~cf)
```

```{r runoff_stats_plot, eval = TRUE, echo = FALSE}

a <- ggplot(centroid_annual %>% ungroup() %>%
         dplyr::select(y, cf, runoff_in) %>%
         pivot_longer(cols = -c(cf,y), values_to = "vals", names_to = "vars") %>%
         mutate(name = case_when(vars == "runoff_in" ~ "Runoff (in)")),
       aes(x = y, y = vals, color = cf)) + 
  geom_line(size = 0.5) + 
  geom_smooth(span = .2, size = 1, se = FALSE) +
  labs(x = "", y = "") +
  scale_color_manual("",values = c("darkgray","red","dodgerblue3")) +
  theme_bw() +
  ylab("Runoff (in)")

b <- ggplot(doy %>% filter(vars == "runoff_in"), aes(x = ym, y = vals, color = cf)) + 
  geom_line(size = 0.5) + 
  geom_smooth(span = .2, size = 1, se = FALSE) +
  scale_x_date(date_breaks = "2 month", date_labels =  "%b")  + 
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "", y = "") +
  scale_color_manual("",values = c("darkgray","red","dodgerblue3"))

ggarrange(a,b, common.legend = TRUE, legend="bottom", align = 'h')

ggsave('data/Test_Figures/runoff_stats.jpg', width = 6, height = 3, units = c("in"),
       dpi = 600)

```

Plot visitor trends

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
ggplot() +
  geom_point(aes(x = visitors_annual$year, 
          y = visitors_annual$TotalVisitors)) + 
  stat_smooth(aes(x = visitors_annual$year, 
          y = visitors_annual$TotalVisitors,col = "Historic"), 
          method = "lm",linetype = "dashed") +
  geom_line(aes(x = visitors_proj$year, y = visitors_proj$p[,1], 
                col = "projected"),
             linetype = "dashed", size = 1) +
  geom_ribbon(aes(x = visitors_proj$year, ymin = visitors_proj$p[,2], 
              ymax = visitors_proj$p[,3], color = "projected"),fill = "dodgerblue", alpha = 0.2, linewidth = 0) +
  labs(x = paste("Year\n\nAdj R2 = ",signif(summary(visitor_trend)$adj.r.squared, 5),
                     " Slope =",signif(visitor_trend$coef[[2]], 5),
                     " P =",signif(summary(visitor_trend)$coef[2,4], 5)),
        y = "Annual Visitors") +
  theme_minimal() + 
  scale_color_manual("",values = c("black","dodgerblue4"))
```

```{r runoff_threshold_plot, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Plot years where runoff crosses threshold

a=ggplot() + geom_line(data = centroid_annual, aes(x = y, y = runoff_in, color = cf)) + geom_hline(yintercept = historic$QLOW, linetype = "dashed") + geom_hline(yintercept = historic$QHIGH, linetype = "dashed") + geom_point(data = filter(streak_check, low_year == 1 \| high_year == 1), aes(x = y, y = runoff_in, color = cf)) + theme_minimal() + labs(x = "",y = "Runoff (in)",color = "") + scale_color_manual("",values = c("darkgray","red","dodgerblue"))

b = ggplot() + geom_point(data = streak_check, aes(x = y, y = low_year - 1, color = cf, fill = cf), shape =22,cex = 3) + geom_point(data = streak_check, aes(x = y, y = high_year, color = cf, fill = cf), shape = 22, cex = 3) + scale_y_continuous(breaks = c(0, 1), labels = c(expression(paste("\< ", P[10], " Historic")), expression(paste("\> ", P[90], " Historic")))) + ylab("") + theme_minimal() + theme(legend.position = "none") + scale_color_manual("",values = c("darkgray","red","dodgerblue")) + scale_fill_manual("",values = c("darkgray","red","dodgerblue"))

ggarrange(a, b, ncol =1, align = "v", heights = c(5,1))

ggsave('data/Test_Figures/runoff_streaks.jpg', width = 6, height = 4, units = c("in"), dpi = 600)

ggplot(stats %\>% pivot_longer(cols = c(precip_in_mean, runoff_in_mean, aet_in_mean), values_to = "vals", names_to = "vars"), aes(x = "", y = vals, fill = vars)) + geom_bar(stat = "identity", width = 1, color = "white") + coord_polar("y",start=0) + scale_fill_manual("",values = c("#E69F00","#009E73","#0072B2"), labels = c("AET","Precipitation", "Runoff")) + facet_wrap(\~cf, scales = "free_y") + theme_void()

```

