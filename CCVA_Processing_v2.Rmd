---
title: "CCVA_Processing"
author: "KEC"
date: "2024-04-04"
output: html_document
editor_options: 
  chunk_output_type: console
---

## CCVA Data Processing

This R markdown prepares data inputs for a Climate Change Vulnerability 
Assessment (CCVA) for water supplies at a selected National Park.

### 1. Setup Workspace

First, install and/or load required packages and functions.

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

source('setup.R')
library("readxl")
library("trend")

```

Various climate, hydrology, and geography data are required to generate a CCVA 
for the selected National Park. The following code chunks download and describe 
this data.

### 2. Park data

Start by specifying which National Park to obtain data for by assigning the 
"park" variable with the four digit Unit List code. Codes for all parks can be 
found at: <https://www.nps.gov/aboutus/foia/upload/NPS-Unit-List.xlsx>.

Once the park is specified, download the park boundary from the NPS IRMA 
DataStore as an sf object.

```{r park_dat, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

park <- "CARE"

# Get park geometry and metadata
park_boundary <- getParkBoundary(park = park)
state <- park_boundary$STATE
park_name <- park_boundary$UNIT_NAME
park_name_short <- gsub(" National Park", "", park_name)

# Define a color palette to use throughout - note can change for regions? feels?
pal = c("#DFCB34","#0067A2", "#CB7223", "#289A84", "#7FA4C2", "#AF7E56","#8C2B0E", "#FEB359", "#132F5B", "#435F90", "#68434E", "#B47E83", "#444E7E", "red","hotpink", "#B7ABBC")#FD8700", "#D8511D")

# Define report name
report_name <- 
  paste0("Climate Change Vulnerability Assessment for Water Supplies at ",
         park_name)

```

Data import option

Read in data if you've already downloaded it
```{r read_data}

# Commented out for now because this is old data.

## path to data folder (from project directory)
#path <- "data/park/"

# read in data
#try(
#load(paste0(path, "/", park, "/", park, "_report_data_v2.RData")))
## terra object issue when saving as .RData, so saved as separate .tif
```


### 3. Water Supply Database

A water supply system database was created for this project using various NPS
and public databases.  The database contains a "supply" table and a "source"
table.  The "supply" table includes a row for each water supply system at
the park. The source table contains a row for each source of water (e.g.,
individual wells, diversions, and springs) associated with each supply. The
two tables are related by a shared column -> wsd_system_id.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

table_path <- "data/Water_Supply_Systems/NPS_Water_Systems_Database.xlsx"

# Supply table (Currently filtered to Utah)
supply_table <- read_excel(table_path, sheet = 2, na = "NA") %>%
  janitor::clean_names() %>%
  dplyr::filter(park_name == park_boundary$UNIT_NAME,
                in_use == "Active")
  
# Source table
source_table <- read_excel(table_path, sheet = 3, na = "NA") %>%
  janitor::clean_names() %>%
  #dplyr::filter(state == "UT")
  dplyr::filter(wsd_system_id %in% supply_table$wsd_system_id) %>%
  dplyr::mutate(well_depth = as.numeric(well_depth))

# Copy of source table as sf_object - some columns without location data are
# dropped. Circle back to this later.
source_table_locs <- source_table %>%
  drop_na(c("source_longitude", "source_longitude")) %>%
  st_as_sf(., 
           coords = (c("source_longitude","source_latitude")), 
           crs = 4326,
           remove = FALSE) 

# Optional preview water source locations
mapviewOptions(fgb = FALSE, 
               georaster = FALSE, 
               basemaps = c("Esri.WorldTopoMap", 
                            "Esri.WorldImagery"))
mapview(source_table_locs,
        zcol = "water_system_name",
        layer.name = "Source:",
        col.regions = pal) + 
  mapview(park_boundary,
          col.regions = "forestgreen",
          alpha.regions = 0.2,
          legend = FALSE)


```

### 4. Source Water 

```{r source_water}

source_table_locs <- get_aoi_source(source_table_locs) %>%
   dplyr::mutate(aoi2 = bind_rows(aoi) %>% 
                   st_make_valid() %>% 
                   st_union()) 

aoi_buff <- dplyr::summarize(st_buffer(source_table_locs, 0.1))

source_aoi <- source_table_locs$aoi2 %>%
  st_crop(., aoi_buff) %>%
  st_union()

mapview(source_aoi)

mapviewOptions(fgb = FALSE, 
               georaster = FALSE, 
               basemaps = c("Esri.WorldTopoMap"))#,
#                            "Esri.WorldImagery"))

mapview(source_table_locs,
        zcol = "water_system_name",
        layer.name = "Source:",
        col.regions = pal,
        cex = 4,
        homebutton = FALSE) + 
  mapview(park_boundary,
          col.regions = "forestgreen",
          alpha.regions = 0.2,
          homebutton = FALSE,
          legend = FALSE) +
  mapview(source_table_locs$aoi %>% bind_rows(),
          zcol = "name",
          layer.name = "AOIs",
          col.regions = pal,
          homebutton = FALSE,
          alpha.regions = 0.2) 



```

### 5. Diversions

Park water supplies may be sourced from within or beyond the park boundary. This
chunk pulls in state-reported water supply locations, or points of diversion (PODS)
that occur within a buffer distance of the park boundary. Then, PODs are filtered
to identify specific PODs associated with park water supplies. For some parks, 
the water supply system ID is linked using the water supply database. For 
others, we assume the water supply is any POD owned by NPS within the select buffer.

\*\*\*\*KEC: This assumes POD_state has "OWNER" column and that NPS is 
identified by string "NATIONAL PARK". Should probably update match strings in 
future as other POD databases are brought in.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Now, get state specific points of diversion (POD) (i.e., water supply points)
# EDIT NOTE - Eventually nest into a getPODall function with aoi and dist
# args which then applies the state-specific function.

# Set distance and AOI for POD search
buffer_dist <- .1 # in decimal degrees lat/long

aoi <- 
  park_boundary

# Dictionary to map POD functions to states
POD_dict <- c(
  "CA" = getPODCalifornia,
  "CO" = getPODColorado,
  "MT" = getWaterRightsMontana,
  "NV" = getPODNevada,
  "UT" = getPODUtah
)

# Assign POD_state using the condition map
if (state %in% names(POD_dict)) {
  
  POD_state <- POD_dict[[state]](aoi, buffer_dist)  # Pass additional arguments

  } else {
    
  print("No PODs returned.")

  }


# Filter using water supply database to identify PODs associated park water 
# supplies. If table does not have adequate information, select by POD
# owner and location metadata

if(supply_table %>% drop_na(water_rights_id) %>% nrow() > 0) {
  
  POD_supply <- POD_state %>%
    #dplyr::filter(WRNUM %in% c("61-893", "2061001M00")) %>%
    dplyr::filter(WRNUM %in% supply_table$water_rights_id) %>%
    dplyr::distinct(LOCATION, .keep_all = TRUE) %>%
    dplyr::left_join(., supply_table %>% 
                       dplyr::select(water_rights_id , water_system_name), 
                     by = c("WRNUM" = "water_rights_id"))

  
} else {
    
  POD_supply <- POD_state %>%
    dplyr::filter(
      OWNER %like% "NATIONAL PARK",
      str_detect(SUMMARY_ST, "A|P")) %>% # approved / perfected applications
      #str_detect(USES,"D|M|O|I")) %>%  # filter by POD use category
    dplyr::distinct(WRNUM,
                    .keep_all = TRUE) %>%
    mutate(name = source)
      
      #if (nrow(Suppliers) >= 1) {
      #  POD_supply <- POD_supply %>%
      #    left_join(., Suppliers, by = WRID)
      #}
}

# All PODS within park
POD_all <- 
  POD_state %>% 
  dplyr::filter(park_right == "Park") %>% 
  dplyr::distinct(WRNUM, .keep_all = TRUE)

mapview(POD_supply,
        zcol = "water_system_name")


```


### 7. Selected Climate Futures

Climate futures were previously compiled for park and Koppen centroids. This
data was used to select which of the CMIP5 climate models to use to represent
"hot dry" and "warm wet" scenarios. 

Source for Koppen-Geiger climate classification maps:

Beck, H. E., Zimmermann, N. E., McVicar, T. R., Vergopolan, N., Berg, A., & 
Wood, E. F. (2018). Present and future KÃ¶ppen-Geiger climate classification maps
at 1-km resolution. Scientific data, 5(1), 1-12.

<https://figshare.com/articles/dataset/Present_and_future_K_ppen-Geiger_climate_classification_maps_at_1-km_resolution/6396959/2>


```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}


select_cfs <- data.table::fread('data/parkwide_gcms_wbm_filtered.csv') %>%
  dplyr::filter(park %in% {{park}},
                  CF %in% c("Warm Wet", "Hot Dry")) %>%
  distinct(GCM, .keep_all = TRUE)

# If there is more than one model selection for a CF scenario, grab the more
# divergent.
if (nrow(select_cfs) > 2) {
  if (nrow(select_cfs %>% dplyr::filter(CF == "Hot Dry")) > 1) {
        select_cfs <- select_cfs %>%
                group_by(CF) %>%
                slice_min(delta_pr)
  }
  if ((nrow(select_cfs %>% dplyr::filter(CF == "Warm Wet")) > 1) ) {
          select_cfs <- select_cfs %>%
            group_by(CF) %>%
            slice_max(delta_pr)
  }
}



```


### 8. Climate data 

Get historical (GridMET) and future (MACA GCMs) climate data for the watersupply
watershed (source area).

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get historical climate data for water source area
clim_source_hist <- 
  get_climate_historic(
    sf = source_aoi,
    col_name = "name",
    start = "1979-01-01",
    end = "2023-12-31"
    ) %>%
  # convert daily values for each grid cell to daily mean for all cells
  dplyr::mutate(CF = "Historical")
                                        

# Get future climate data for water source area

tictoc::tic()
clim_source_fut <- 
  get_climate_future(
    sf = watersupply_watershed,
    col_name = "name",
    start = "2006-01-01",
    end = "2070-01-01",
    GCM = select_cfs$GCM
    ) %>%
  dplyr::mutate(GCM = paste0(GCM,'.',RCP)) %>%
  left_join(select_cfs %>% dplyr::select(c("GCM","CF")), by = c("GCM")) %>%
  dplyr::select(-c("GCM","Ensemble","RCP")) 

tictoc::toc()



# Get historical climate data for nearest NWIS stream gage
clim_nwis <- 
  get_climate_historic(
    sf = nwis_nearest_watershed,
    col_name = "site_no",
    start = nwis_nearest_discharge$date %>% min(),
    end = "2023-01-01") %>%
  dplyr::mutate(CF = "Historical") %>%
  # Join wbm results with discharge
  left_join(., nwis_nearest_discharge , by = c("date", "site_no")) 

# Get unique points from each climate dataset
source_fut_pts <- clim_source_fut %>% 
  ungroup() %>% 
  distinct(x,y, .keep_all = TRUE) %>% 
  st_as_sf(., coords = c("x","y"), crs = st_crs(4326), remove = FALSE) %>%
  dplyr::select(c(date,CF,name,x,y))

source_hist_pts <- clim_source_hist %>% 
  ungroup() %>% 
  distinct(x,y, .keep_all = TRUE) %>% 
  st_as_sf(., coords = c("x","y"), crs = st_crs(4326), remove = FALSE) %>%
  dplyr::select(c(date,CF,name,x,y))

nwis_pts <- clim_nwis %>% 
  ungroup() %>% 
  distinct(x,y, .keep_all = TRUE) %>% 
  st_as_sf(., coords = c("x","y"), crs = st_crs(4326), remove = FALSE) %>%
  dplyr::select(c(date,CF,site_no,x,y))

# Plot
mapview(source_fut_pts, 
        col.regions = "black",
        layer.name = "MACA") + 
  mapview(watersupply_watershed, 
          col.regions = "dodgerblue", 
          alpha.regions = 0.2,
          layer.name = "Source Watershed") + 
  mapview(source_hist_pts, 
          col.regions = "red",
          layer.name = "GridMET") +
mapview(source_hist_pts %>% 
          st_transform(., 32612) %>% 
          st_buffer(, dist = 2000),
        col.regions = "red",
        alpha.regions = 0.2,
        legend = FALSE) +
  mapview(nwis_pts,
          col.regions = "red",
          legend = FALSE) +
  mapview(nwis_nearest_watershed,
          col.regions = "seagreen",
          alpha.regions = 0.3,
          layer.name = "NWIS Watershed")

```

### 9. WBM 

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
# run_nps_wbm()
 
```

##### 3.7. USGS Data

For many parks, the nearest USGS stream gage is far away. Therefore, we are 
pulling all NWIS gages within 100 km of the park boundary. Of those, we only 
select stream gages that are considered "reference" gages in the 
[GAGES-II database (Falcone, 2011)](https://pubs.usgs.gov/publication/70046617).
Then, we delineate each of those gages' watersheds using the `get_nldi_basin()` 
function from the {nhdplusTools} package:

```{r, eval = TRUE, message = FALSE, warning = FALSE}

# Get all NWIS sites
nwis <- listNWIS(aoi = source_aoi %>% 
                   st_as_sf() %>% 
                   st_transform(crs = st_crs(park_boundary)), dist = .3) #%>%


  #dplyr::filter(data_type_cd == "dv",
  #       code == "00060")

# Get NWIS Stream Gages
ref_gages <- get_gagesII(id = nwis$site_no) %>%
             dplyr::filter(class == "Ref")

nwis_stream <- nwis %>%
              dplyr::filter(site_no %in% ref_gages$staid,
                            data_type_cd == "dv") %>%
              dplyr::left_join(st_drop_geometry(ref_gages), 
                               by = c("site_no" ="staid")) 

# Download data from reference stream sites
nwis_stream_discharge <- 
  dataRetrieval::readNWISdv(siteNumbers = nwis_stream$site_no,
                            parameterCd = c('00060','00065')) %>%
    dplyr::mutate(y = year(Date), m = month(Date)) %>%
    dplyr::filter(y >= 1980) %>%
    dplyr::group_by(y,m, site_no) %>%
    dplyr::summarize(mean_discharge = mean(X_00060_00003, na.rm. = TRUE),
                     .groups = "keep") %>%
    dplyr::ungroup() %>%
    dplyr::mutate(ym = lubridate::make_date(year = y, month = m, day = 1)) %>% 
    dplyr::select(ym, site_no, mean_discharge) %>%
    tidyr::pivot_wider(names_from = site_no, 
                       names_prefix = "gage_", 
                       values_from = mean_discharge) #%>%

# Download data from reference stream sites
#getNWIS(inventory = nwis_stream, park = "misc", path = "data/")


# Define functions to get those watersheds for ref. gages using get_nldi_basin 
# in from {nhdplusTools}.

# ================ Function to identify NLDI watersheds ========================


# Now, use functions to get watersheds associated with stream gages
nldi_watershed <- 
  nwis_stream$site_no %>%
  purrr::map_dfr(~nldi_finder(site_no = .)) %>%
  dplyr::mutate(data = map(site_no, ~nldi_meta(site_no = .))) %>%
  unnest(cols = c(data)) %>%
  dplyr::left_join(st_drop_geometry(nwis), by = "site_no")

nldi_flowlines <- 
  dplyr::summarize(nldi_watershed) %>%
  mapNHDPlusHR() %>% 
  dplyr::summarize()


# Now Get Gw sites

nwis_groundwater <- nwis %>%
  dplyr::filter(begin_date != end_date,
                n_obs > 50,
                # groundwater sites only:
                site_type_cd == "GW",
                data_type_cd == "gw",
                code == 72019) %>%
  dplyr::mutate(dist = st_distance(geometry,park_boundary) %>%
                as.numeric()) %>%
  dplyr::filter(dist <= 1600*3) %>%
  add_gw_meta()


# pull those sites groundwater level data and convert to monthly mean
  nwis_groundwater_levels <- 
    dataRetrieval::readNWISgwl(nwis_groundwater$site_no) %>%
    dplyr::filter(parameter_cd == 62611,
                  year(lev_dt) >= 1980) %>% # 72019 =Depths, 62611=elevation
    dplyr::mutate(ym = lubridate::ym(substr(lev_dt, 1, 7))) %>% 
    dplyr::group_by(ym, site_no) %>%
    dplyr::summarize(mean_lev_va = mean(sl_lev_va, na.rm. = TRUE), # elevation
                     #mean_lev_va = mean(lev_va, na.rm. = TRUE), # depths
                     .groups = "keep") %>%
    dplyr::select(ym, site_no, mean_lev_va) %>%
    tidyr::pivot_wider(names_from = site_no, names_prefix = "well_", 
                       values_from = mean_lev_va) #%>%


```

#### 3.8. Park Visitation

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
# NPS monthly visitor information
visitors <- 
  getUnitVisitation(units = park, startYear = 1980, endYear = 2023) %>%
  dplyr::mutate(ym = ym(paste0(Year, "-", Month))) %>%
  dplyr::mutate(TotalVisitors = RecreationVisitors + NonRecreationVisitors) %>%
  dplyr::select(ym, RecreationVisitors, TotalVisitors) %>%
  mutate(ifelse(TotalVisitors == 0,NA,TotalVisitors),
         ifelse(RecreationVisitors ==0, NA, RecreationVisitors))


```

#### 3.9. Water use data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get state specific water use data --> in monthly format

if (state == "UT") {

  water_supply_id <- getWaterSuppliersUtah(aoi = park_boundary) %>%
    filter(grepl("National", WRNAME, ignore.case=TRUE) | 
           grepl("National", WRENAME, ignore.case = TRUE)) %>%
    .$WRID

  if (!sum(water_supply_id)==0) {
  
   water_use <- map_dfr(water_supply_id, 
                     \(x) getWaterUseUtah(WRID = x)[[1]] %>%
      dplyr::filter(!is.na(suppressWarnings(as.numeric(Year)))) %>%
      tidyr::pivot_longer(-c("Year","Method of Measurement"), 
                          names_to = "month", 
                          values_to = "use_acre_feet") %>%
      dplyr::filter(month != "Annual inAcre Feet") %>%
      dplyr::mutate(ym = ym(paste0(Year, "-", month))) %>%
      drop_na(ym) %>%
      dplyr::group_by(ym) %>%
      dplyr::summarize(use_acre_feet = sum(as.numeric(use_acre_feet), 
                                           na.rm = TRUE)) %>%
        mutate(WRID=paste0("WRID_",x))) %>%
     pivot_wider(names_from = WRID, values_from = use_acre_feet) %>%
     mutate(use_acre_feet = rowSums(dplyr::select(., !starts_with("ym")), 
                                    na.rm = TRUE))
  
  } else if (water_supply_id == 0 ) {
    water_use = Visitors %>%
      mutate(water_use_gal = TotalVisitors*5)
    }

}
```

### 4. Data Analysis

###### 4.1 Data munging

Before we can analyze all the data we've accumulated, we must aggregate data into daily, monthly, seasonal, and yearly sets. In this section, we join the previously amassed datasets and calculate some general statistics.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Set date range for historic and future aggregation periods
hist_years <- c(1980,2010)      # 30 year
future_years <- c(2040,2070)   # 30 year

# For temporal aggregations, some variables will be summarized using the mean 
# while others will use the sum. Define which cols for subsequent calculations
mean_cols <- c("tavg_f", "tmax_f","tmin_f", "r_hmax_percent", "r_hmin_percent",
               "deficit_in", "soil_water_in", "runoff_in", "accumswe_in")

sum_cols <- c("precip_in", "rain_in", "snow_in","aet_in", "pet_in", 
              "days_gt_92F", "days_lt_32F", "days_gt_95pcp", "days_gt_95roff", 
              "days_gt_77F", "days_lt_05roff", "days_w_pcp","days_w_swe")


################################ Daily Stats ###################################

# First, calculate some generic stats on daily data for historic and future
# periods of interest

# Join centroid data -- daily frequency
centroid_all <- left_join(centroid_climate %>%
                            dplyr::filter(!is.na(cf)), # remove non-selected cfs
                          centroid_wbm %>%
                            dplyr::filter(!is.na(cf)), 
                by = c("date","gcm","cf", "centroid","unit_climate_zone")) %>%
                mutate(snow_in = precip_in - rain_in)

# Calculate some generic stats for all variables using daily data
stats <- centroid_all %>%
  dplyr::mutate(stat_group = 
               dplyr::case_when(year(date) > hist_years[1] & 
                                year(date) < hist_years[2] ~ "Historical",
                                year(date) > future_years[1] & 
                                year(date) < future_years[2] ~ "Future")) %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::select(-c(date, gcm, unit_climate_zone, centroid)) %>%
  dplyr::group_by(cf,stat_group) %>%
  dplyr::summarize_all(.funs = 
                        list(Q95 = ~ quantile(., probs = 0.95, na.rm = TRUE),
                             Q05 = ~ quantile(., probs = 0.05, na.rm = TRUE),
                            mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")


# Now, add binary indicator to get day counts (e.g., 1 for days over X degrees,
# 0 for days under X degrees)
centroid_all <- centroid_all %>%
  group_by(cf) %>%
      # Get day counts for conditional statistics
      dplyr::mutate(days_gt_92F = ifelse(    tmax_f > 92, 1, 0),
                    days_gt_77F = ifelse(    tmax_f > 77, 1, 0),
                    days_lt_32F = ifelse(    tmin_f < 32, 1, 0),
                    days_w_pcp = ifelse(  precip_in >  0, 1, 0),
                    days_w_swe = ifelse(accumswe_in >  0, 1, 0),
                  days_gt_95pcp = ifelse(precip_in >= stats[stats$stat_group == 
                                              "Historical",]$precip_in_Q95,1,0),
                 days_gt_95roff = ifelse(runoff_in >= stats[stats$stat_group == 
                                              "Historical",]$runoff_in_Q95,1,0),
                 days_lt_05roff = ifelse(runoff_in <= stats[stats$stat_group == 
                                              "Historical",]$runoff_in_Q05,1,0))

############################## Seasonal Stats ##################################

# Create Seasonal Dataframe
centroid_seasonal <- centroid_all %>%
  dplyr::mutate(season = case_when(month(date) %in% c(12,1,2) ~ "Winter",
                            month(date) %in% c(3,4,5) ~ "Spring",
                            month(date) %in% c(6,7,8) ~ "Summer",
                            month(date) %in% c(9,10,11) ~ "Fall")) %>%
  dplyr::mutate(y = year(date)) %>%
  dplyr::select(-c(date,gcm)) %>%
  dplyr::group_by(y,season,cf)%>%
  dplyr::summarize(
              across(all_of(sum_cols),sum),  # Sum of columns in sum_cols list
              across(all_of(mean_cols),mean),
              peak_swe_in = max(accumswe_in),
              peak_runoff_in = max(runoff_in),
              .groups = "keep")


seasonal_stats <- centroid_seasonal %>%
  dplyr::mutate(stat_group = 
                  ifelse(y > hist_years[1] & y < hist_years[2], "Historical",
                  ifelse(y > future_years[1] & y < future_years[2], 
                                    "Future",NA))) %>%
  dplyr::ungroup() %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::group_by(cf,stat_group,season) %>%
  dplyr::summarize_all(.funs = 
                        list(mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")
  
############################## Monthly Stats ###################################

# Create Monthly Dataframe
centroid_monthly <- centroid_all  %>%
  # Group and summarize by month and year
            dplyr::mutate(y = year(date), m = month(date)) %>%
            dplyr::select(-c(date)) %>%
            dplyr::group_by(y,m,gcm,unit_climate_zone,cf) %>%
            dplyr::summarize(
              across(all_of(sum_cols),sum),  
              across(all_of(mean_cols),mean),
                     peak_swe_in = max(accumswe_in),
                     peak_runoff_in = max(runoff_in),
              .groups = "keep") %>%
            dplyr::mutate(ym = make_date(y,m), .before = gcm) %>%
            dplyr::ungroup() %>%
            dplyr::select(-c(y,m)) %>%
  # Add other monthly datasets to monthly
            dplyr::left_join(nwis_groundwater_levels, by = c("ym")) %>%
            dplyr::left_join(nwis_stream_discharge, by = c("ym")) %>%
            dplyr::left_join(visitors, by = c("ym")) %>%
            dplyr::left_join(water_use,by = c("ym")) %>%
  # calculate some new values
  mutate(demand_pp_af = use_acre_feet/TotalVisitors,
         demand_pp_gal = 325851 * demand_pp_af,
         use_acre_feet = ifelse(use_acre_feet == 0, NA, use_acre_feet))

  
############################### Annual Stats ###################################

# Define new columns that have been added since monthly dataframe was created
new_cols_sum <- c("use_acre_feet","TotalVisitors","RecreationVisitors")
new_cols_mean <- 
  names(nwis_groundwater_levels)[2:length(names(nwis_groundwater_levels))]

# Create annual Dataframe
centroid_annual <- centroid_monthly  %>%
            dplyr::mutate(y = year(ym)) %>%
            dplyr::select(-c(ym)) %>%
            dplyr::group_by(y,gcm,unit_climate_zone,cf) %>%
            dplyr::summarize(
              across(all_of(sum_cols),sum),  # Sum of columns in sum_cols list
              across(all_of(mean_cols), \(x) mean(x, na.rm = TRUE)),
              across(all_of(new_cols_sum),sum),
              across(all_of(new_cols_mean), \(x) mean(x, na.rm = TRUE)),
              peak_swe_in = max(peak_swe_in),
              peak_runoff_in = max(peak_runoff_in),
              .groups = "keep") %>%
          # recalculate demand with annual data
          mutate(demand_pp_af = use_acre_feet/TotalVisitors,
          demand_pp_gal = 325851 * demand_pp_af,
          use_acre_feet = ifelse(use_acre_feet == 0, NA, use_acre_feet))


#save(list = c("centroid_monthly","centroid_annual","watersupply_watershed","park_boundary"),
#     file = "data/Visitation_Demand_Projections/BRCA_dat.Rdata")


# Create dataframe containing annual statistics for historical and future 
# subsets of data
annual_stats <- centroid_annual %>%
  dplyr::mutate(stat_group = 
                  ifelse(y > hist_years[1] & y < hist_years[2], "Historical",
                  ifelse(y > future_years[1] & y < future_years[2], 
                                    "Future",NA))) %>%
  dplyr::ungroup() %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::select(-c(gcm,unit_climate_zone)) %>%
  dplyr::group_by(cf,stat_group) %>%
  dplyr::summarize_all(.funs = 
                        list(mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")

  
```

###### 4.2 Timing, Frequency. & Duration

Climate change will alter the timing, frequency, and duration of various aspects of the hydrological cycle. Herein, we calculate statistics to track changes in the timing, frequency, and duration of variables of interest.

```{r}

# Create a dataframe containing the number of consecutive years that a variable
#meets various thresholds. 

streaks <- streak_finder(df = centroid_annual, 
                          var = "runoff_in", 
                          q1 = 0.1, 
                          q2 = 0.9)


streaks_summary <- streaks %>% 
  pivot_wider(names_from = stat, values_from = streak_length) %>%
  group_by(cf) %>%
  dplyr::summarize(max_high = max(`High Year Streak`, na.rm = TRUE),
            max_low = max(`Low Year Streak`, na.rm = TRUE),
            count_high = sum(`High Year Streak`, na.rm = TRUE),
            count_low = sum(`Low Year Streak`, na.rm = TRUE),
            .groups = "keep") %>%
  mutate(freq_high = ifelse(cf == "Historical", count_high / (2022-1979),
         count_high / (2099-2026)),
         freq_low = ifelse(cf == "Historical", count_low / (2022-1979),
         count_low / (2099-2026))) %>%
  mutate_all(function(x) ifelse(is.infinite(x), 0, x))

q1 <- 0.1
q2 <- 0.9

historic_probs <- centroid_annual %>%
    dplyr::filter(cf == "Historical") %>%
    dplyr::select(runoff_in) %>%
    ungroup() %>%
    dplyr::summarize(QLOW = quantile(runoff_in, probs = as.numeric(q1)),
                     QHIGH = quantile(runoff_in, probs = as.numeric(q2)))

streak_check <- centroid_annual %>%
  mutate(low_year = ifelse(runoff_in <= historic_probs$QLOW, 1, NA),
         high_year = ifelse(runoff_in >= historic_probs$QHIGH, 1, NA)) %>%
  dplyr::select(y, cf, low_year, high_year, runoff_in)



################################. DOY Stats ####################################

doy <- centroid_all %>%
  mutate(doy = yday(date)) %>%
  dplyr::select(-c(gcm, unit_climate_zone, centroid,date)) %>%
  group_by(cf,doy) %>%
  summarize_all(mean) %>%
  dplyr::select(doy, cf, tavg_f, precip_in, accumswe_in, aet_in, snow_in, rain_in,
                deficit_in, runoff_in) %>%
  pivot_longer(cols = -c(cf,doy), values_to = "vals", names_to = "vars") %>%
  mutate(ym = as.Date(doy, origin = "2014-01-01"),
         name = case_when(vars == "accumswe_in" ~ "SWE (in)",
                          vars == "aet_in" ~ "AET (in)",
                          vars == "deficit_in" ~ "Soil Water Deficit (in)",
                          vars == "precip_in" ~ "Precipitation (in)",
                          vars == "runoff_in" ~ "Runoff (in)",
                          vars == "tavg_f" ~ "Temperature (F)",
                          vars == "snow_in" ~ "Snow (in)",
                          vars == "rain_in" ~ "Rain (in)"))
  

############################## Runoff timing ###################################

# here is a bimodal distribution for the day-of-year for the maximum
# precipitation AND correspondingly runoff. 

# Runoff timing 

# Group by year and select daily maximum discharge with corresponding date
max_annual_runoff <- centroid_all %>%
  mutate(Date = date,
         year = year(date)) %>%
  dplyr::select(c(Date,cf,year,runoff_in)) %>%
  addWaterYear() %>%
  dplyr::group_by(cf,waterYear) %>% 
  dplyr::slice_max(order_by = runoff_in, n=1, with_ties = FALSE) %>%
  mutate(doy = yday(Date),
         dowy = as.numeric(Date - as.Date(paste0(waterYear-1,"-10-01"))),
         season = case_when(month(Date) %in% c(12,1,2) ~ "Winter",
                            month(Date) %in% c(3,4,5) ~ "Spring",
                            month(Date) %in% c(6,7,8) ~ "Summer",
                            month(Date) %in% c(9,10,11) ~ "Fall"))


# calculate slopes, or rate of annual change. Negative indicates earlier runoff
spring_runoff_yearly_change <- max_annual_runoff %>%
  filter(season == "Spring" | season == "Winter") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep") %>%
      mutate(dir = case_when(slope < 0 ~ paste0("shifted earlier on average by ",round(slope,1)," days per year"),
                             slope > 0 ~ paste0("shifted later on average by ",round(slope,1)," days per year"),
                             slope == 0 ~ "does not significantly shift"),
             slope_round = abs(round(slope,1)))

fall_runoff_yearly_change <- max_annual_runoff %>%
  filter(season == "Fall" | season == "Summer") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

################################. Peak SWE timing ##############################
# Group by year and select daily maximum discharge with corresponding date
max_annual_swe <- centroid_all %>%
  mutate(Date = date,
         year = year(date)) %>%
  dplyr::select(c(Date,cf,year,accumswe_in)) %>%
  addWaterYear() %>%
  dplyr::group_by(cf,waterYear) %>% 
  dplyr::slice_max(order_by = accumswe_in, n=1, with_ties = FALSE) %>%
  mutate(doy = yday(Date),
         dowy = as.numeric(Date - as.Date(paste0(waterYear-1,"-10-01"))),
         season = case_when(month(Date) %in% c(12,1,2) ~ "Winter",
                            month(Date) %in% c(3,4,5) ~ "Spring",
                            month(Date) %in% c(6,7,8) ~ "Summer",
                            month(Date) %in% c(9,10,11) ~ "Fall"))


# calculate slopes, or rate of annual change. Negative indicates earlier runoff
spring_swe_yearly_change <- max_annual_swe %>%
  filter(season == "Spring" | season == "Winter") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep") %>%
      mutate(dir = case_when(slope < 0 ~ paste0("shifted earlier on average by ",round(slope,1)," days per year"),
                             slope > 0 ~ paste0("shifted later on average by ",round(slope,1)," days per year"),
                             slope == 0 ~ "no significant shifts"),
             slope_round = abs(round(slope,1)))

fall_swe_yearly_change <- max_annual_swe %>%
  filter(season == "Fall" | season == "Summer") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")



################################# Precip timing ################################

max_annual_precip <- centroid_all %>%
  mutate(Date = date,
         year = year(date)) %>%
  dplyr::select(c(Date,cf,year,precip_in)) %>%
  addWaterYear() %>%
  dplyr::group_by(cf,waterYear) %>% 
  dplyr::slice_max(order_by = precip_in, n=1, with_ties = FALSE) %>%
  mutate(doy = yday(Date),
         dowy = as.numeric(Date - as.Date(paste0(waterYear-1,"-10-01"))),
         season = case_when(month(Date) %in% c(12,1,2) ~ "Winter",
                            month(Date) %in% c(3,4,5) ~ "Spring",
                            month(Date) %in% c(6,7,8) ~ "Summer",
                            month(Date) %in% c(9,10,11) ~ "Fall"))

# calculate slopes, or rate of annual change. Negative indicates earlier precip
spring_precip_yearly_change <- max_annual_precip %>%
  filter(season == "Spring" | season == "Winter") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

fall_precip_yearly_change <- max_annual_precip %>%
  filter(season == "Fall" | season == "Summer") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

```

###### 4.3 Visitation

Visitation is a major driver of park water use. In order to predict future water demands, we must also have a sense of future visitation. In this section, we develop models to predict future visitation and calculate some visitation stats.

Importantly,temperature has been identified as a strong predictor of visitation trends at national parks (Fisichelli et al., 2015). citation: Fisichelli NA, Schuurman GW, Monahan WB, Ziesler PS (2015) Protected Area Tourism in a Changing Climate: Will Visitation at US National Parks Warm Up or Overheat? PLoS ONE 10(6): e0128226. <https://doi.org/10.1371/journal.pone.0128226>

Start by plot monthly visitor proportions to see if park visitor data follow temperature relationships identified by Fisichelli et al., 2015. Currently, we use the mean of max daily temperatures (tmax_F) for each month to calculate proportions, but this was also tested with the average daily temp which produced similar results.

```{r}

# identify regression variables
visitor_regress <- purrr::map(
 # Elements to iterate over
  centroid_monthly %>% 
    dplyr::filter(year(ym) < 2024) %>%
    dplyr::select(-c(ym, gcm, cf, unit_climate_zone,TotalVisitors)),
  ~lm(TotalVisitors ~ .x, data = centroid_monthly %>%
        dplyr::filter(year(ym) < 2024))) %>%
  purrr::map(broom::glance) %>%
  dplyr::bind_rows(.id = "variable") %>%
  dplyr::select(variable, r.squared) %>%
  arrange(.,desc(r.squared))


# First test monthly proportions

monthly_proportion <- centroid_monthly %>%
  mutate(y = year(ym)) %>%
  dplyr::filter(y < 2024) %>%
  group_by(y) %>%
  mutate(vis_sum = sum(TotalVisitors, na.rm = TRUE),
         monthly_vis_prop = TotalVisitors/vis_sum,
         dem_sum = sum(use_acre_feet, na.rm = TRUE),
         monthly_dem_prop = use_acre_feet/dem_sum,
         tmax_c = (tmax_f - 32)*5/9) 

a <- ggplot(monthly_proportion) + 
  geom_boxplot(aes(x = floor(tmax_c), 
                   y = monthly_vis_prop, 
                   group = floor(tmax_c))) + 
  labs(x = "Monthly Temperature (C)", 
       y = "Monthly visitation (proportion)",
       title = park_name)

b <- ggplot(monthly_proportion) + 
  geom_boxplot(aes(x = floor(tmax_c), 
                   y = monthly_dem_prop, 
                   group = floor(tmax_c))) + 
  labs(x = "Monthly Temperature (C)", 
       y = "Monthly water demand (proportion)",
       title = park_name)

ggarrange(a,b,nrow = 1)


# At BRCA -- monthly visitation does not appear to decrease over 77 degrees F,
# as predicted by Fisichelli. So....

# Develop a multiple linear regression model that uses mean monthly temperature, 
# the number of days per month with temperatures greater than 77F, and the year 
# to predict # monthly park visitors.

# Function to create a population curve from the year. The "2000" can be 
# modified to change where the population curve peaks. May want to explore more
pop_curve <- function(year, k = 0.1, L = 20) {
  ymean <- mean(year, na.rm = TRUE)
  pop <- (L / (1 + exp(-k * (year - 1985)))) + 1
}



# Add new variabls to df
centroid_monthly <- centroid_monthly %>%
                   mutate(TotalVisitorsLog = log(TotalVisitors),
                          y = year(ym), 
                          m = month(ym),
                          pop = pop_curve(y)) 

plot(centroid_monthly$ym, centroid_monthly$pop)

# Develop model
visitor_mlr = lm(formula = TotalVisitorsLog ~ 
                    tavg_f +
                    days_gt_77F +
                    days_lt_32F +
                    #days_w_swe +
                    pop,
                   data = centroid_monthly %>%
                   filter(year(ym) <= 2023))

print(summary(visitor_mlr))


# Add projections to monthly dataframe
centroid_monthly <- 
  mutate(centroid_monthly,
            TotalVisitors_mlr_fit = exp(predict(visitor_mlr, centroid_monthly)),
            TotalVisitors_mlr_lwr = exp(predict(visitor_mlr, centroid_monthly, 
                                            interval = "confidence")[,2]),
            TotalVisitors_mlr_upr = exp(predict(visitor_mlr, centroid_monthly, 
                                            interval = "confidence")[,3]),
         TotalVisitors_all = case_when(year(ym) < 2024 ~ TotalVisitors,
                                       year(ym) >= 2024 ~ TotalVisitors_mlr_fit),
         TotalVisitorsLog = log(TotalVisitors_all))



if ("TotalVisitors_mlr_fit" %in% names(centroid_annual)) {
          centroid_annual <- centroid_annual %>%
          dplyr::select(-c(TotalVisitors_mlr_fit,TotalVisitors_mlr_lwr,TotalVisitors_mlr_upr))
 }

# Sum and add to annual dataset
centroid_annual <- centroid_monthly %>%
  dplyr::select(-c(ym,gcm,unit_climate_zone)) %>%
  group_by(y,cf) %>%
  dplyr::summarize(TotalVisitors_mlr_fit = sum(TotalVisitors_mlr_fit, na.rm = FALSE),
            TotalVisitors_mlr_lwr = sum(TotalVisitors_mlr_lwr, na.rm = FALSE),
            TotalVisitors_mlr_upr = sum(TotalVisitors_mlr_upr, na.rm = FALSE),
            .groups = "keep") %>%
  left_join(., centroid_annual, by = c("y","cf")) %>%
  mutate(TotalVisitors_all = case_when(y < 2024 ~ TotalVisitors,
                                       y >= 2024 ~ TotalVisitors_mlr_fit),
         TotalVisitors_log = log(TotalVisitors_all))

# Plot monthly visitors
ggplot(centroid_monthly %>% filter(year(ym) < 2070)) + 
  geom_line(aes(x = ym, 
                y = TotalVisitors_mlr_fit, 
                color = cf), 
            size = 1) +
  geom_ribbon(aes(x = ym, 
                  ymin = TotalVisitors_mlr_lwr, 
                  ymax = TotalVisitors_mlr_upr),
              alpha = 0.3,
              fill = "hotpink") +
  geom_line(aes(x = ym, 
                y = TotalVisitors,color = "historical_actual"), 
            size = 1) + 
  scale_color_manual("",
                     values = c("hotpink","black","red","cornflowerblue"), 
                     labels = c("MLR Model","Historical","Hot Dry", "Warm Wet" )) + 
  labs(x = "", y = "Total Monthly Visitors", title = "BRCA") + 
  theme_bw() #+ coord_trans(y = "log10") 

#ggsave('data/Test_Figures/Visitors_Proj_Model.jpg', width = 8, height = 4, units = c("in"),
 #      dpi = 600)

annual_visitor_summary <- centroid_annual %>%
  dplyr::select(y,cf,TotalVisitors_all) %>%
  dplyr::filter(y >= 2000) %>%
  group_by(cf) %>%
  drop_na(TotalVisitors_all) %>%
  dplyr::summarize(sens_slope = trend::sens.slope(TotalVisitors_all)$estimates[1],
                   pval = trend::sens.slope(TotalVisitors_all)$p.value,
                   mean = mean(TotalVisitors_all),
                   percent_chg = 100*trend::sens.slope(TotalVisitors_all)$estimates[1] / mean(TotalVisitors_all)) %>%
  mutate(text = case_when(sens_slope < 0 & pval < 0.05 ~ paste0("decreased on average by ",round(percent_chg,1)," % per year"),
                          sens_slope > 0 & pval < 0.05 ~ paste0("increased on average by ",round(percent_chg,1)," % per year"),
                          sens_slope == 0 | pval > 0.05 ~ "not significantly changed"))

```

###### 4.4 Water Demand

Next, we'll use visitation projections to make estimates about future demands. Again, we'll develop models to predict future water demands using historical data and then we'll project models into the future.

```{r demand_per_person_plots, warning = FALSE, echo = FALSE, fig.width =5}

# Start by looking at general trends in use and per person demand

a <- ggplot(centroid_monthly %>% filter(year(ym) < 2024),
            aes(x = ym, y = demand_pp_gal)) + 
  geom_point(color = "dodgerblue") +
  geom_smooth(color = "dodgerblue4",fill = "dodgerblue4") + 
  labs(y = "Monthly", x = "", 
       title = "      Water Use (gallons per person)") +
  theme_bw()

b <- ggplot(centroid_annual %>% filter(y < 2024), 
            aes(x = y, y = demand_pp_gal)) + 
  geom_point(color = "dodgerblue") + 
  geom_smooth(color = "dodgerblue4",fill = "dodgerblue", span = 1) + 
  labs(y = "Annual", x = "") +
  theme_bw()

ggarrange(a,b, nrow = 2)

```

Next, Develop models to predict future water demand .

```{r }

# First create calibrated model with historic data then project.

# identify regression variables
use_regress <- purrr::map(
 # Elements to iterate over
  centroid_monthly %>% 
    dplyr::filter(y < 2024) %>%
    dplyr::select(-c(ym, gcm, cf, unit_climate_zone,use_acre_feet)),
  ~lm(use_acre_feet ~ .x, data = centroid_monthly %>%
        dplyr::filter(y < 2024))) %>%
  purrr::map(broom::glance) %>%
  dplyr::bind_rows(.id = "variable") %>%
  dplyr::select(variable, r.squared) %>%
  arrange(.,desc(r.squared))


# Next try multiple linear regression which uses multiple inputs
demand_mlr_model = lm(formula = use_acre_feet ~ 
                    tmax_f +
                    days_lt_32F +
                   TotalVisitorsLog +
                     pet_in,
                 data = centroid_monthly %>%
                              filter(year(ym) < 2023) %>%
                              mutate(use_acre_feet = 
                                ifelse(use_acre_feet == 0, NA, use_acre_feet)))

print(summary(demand_mlr_model))

centroid_monthly <- 
  mutate(centroid_monthly,
            MLR_demand_fit = predict(demand_mlr_model, centroid_monthly),
            MLR_demand_lwr = predict(demand_mlr_model, centroid_monthly, interval = "confidence")[,2],
            MLR_demand_upr = predict(demand_mlr_model, centroid_monthly, interval = "confidence")[,3],
         demand_all = case_when(year(ym) < 2024 ~ use_acre_feet,
                                year(ym) > 2024 ~ MLR_demand_fit))


# How does it do for annual predictions
demand_annual <- centroid_monthly %>%
  dplyr::select(c('y','use_acre_feet','MLR_demand_fit','cf')) %>%
  group_by(y,cf) %>%
  summarize_all(list(sum))

r_squared <- cor(na.omit(demand_annual) %>% pull(use_acre_feet), 
                 na.omit(demand_annual) %>% pull(MLR_demand_fit))^2

# What if instead you calibrate the model to annual data

# identify regression variables
use_regress_annual <- purrr::map(
 # Elements to iterate over
  centroid_annual %>% 
    ungroup() %>%
    dplyr::filter(y < 2024) %>%
    dplyr::select(-c(gcm, cf, unit_climate_zone, use_acre_feet)),
  ~lm(use_acre_feet ~ .x, data = centroid_annual %>%
        dplyr::filter(y < 2024))) %>%
  purrr::map(broom::glance) %>%
  dplyr::bind_rows(.id = "variable") %>%
  dplyr::select(variable, r.squared) %>%
  arrange(.,desc(r.squared))


# multiple linear regression
demand_mlr_modelA = lm(formula = use_acre_feet ~ 
                    tavg_f +
                    days_gt_95roff + 
                    TotalVisitors_all+
                     aet_in +
                     snow_in,
                 data = centroid_annual %>%
                        filter(y < 2023) %>%
                        mutate(use_acre_feet = 
                            ifelse(use_acre_feet == 0, NA, use_acre_feet)))

summary(demand_mlr_modelA)

centroid_annual <- centroid_annual %>%
  mutate(MLR_demandA_fit = predict(demand_mlr_modelA, newdata = centroid_annual),
         MLR_demandA_lwr = predict(demand_mlr_modelA, newdata = centroid_annual, interval = "confidence")[,2],
         MLR_demandA_upr = predict(demand_mlr_modelA, newdata = centroid_annual, interval = "confidence")[,3],
         demand_all = case_when(y < 2024 ~ use_acre_feet,
                                y > 2024 ~ MLR_demandA_fit))


# Plot both models for yearly values

# Doesn't do great for annual water use -- so develop separate annual model
a <- ggplot(demand_annual %>% 
         filter(y < 2025) %>%
         mutate(use_acre_feet = ifelse(use_acre_feet == 0, NA, use_acre_feet)) %>%
         drop_na(use_acre_feet) %>%
         pivot_longer(cols = -c(y,cf), names_to = 'vars', values_to = 'vals'),
         aes(x = y, y = vals, color = vars)) + 
  geom_line(size = 1) + 
  scale_color_manual("", values = c("hotpink","black"),
                         labels = c("MLR Model","Actual")) + 
  labs(x = "", y = "Annual Water Use (af)", title = "Monthly Model") +
  theme_bw()

b <- ggplot(centroid_annual  %>% 
         filter(y < 2025) %>%
         mutate(use_acre_feet = ifelse(use_acre_feet == 0, NA, use_acre_feet)) %>%
         drop_na(use_acre_feet)) + 
  geom_line(aes(x = y, y = use_acre_feet,
             color = "Actual Use"), size = 1) +
geom_line(aes(x = y, 
              y = MLR_demandA_fit,
             color = "MLR Model"), size = 1) +
  scale_color_manual("", values = c("black","hotpink")) +
  labs(x = "", y = "Annual Water Use", title = "Annual Model") + theme_bw() 

ggarrange(a,b,nrow = 2)

ggsave('data/Test_Figures/Demand_Historic_Annual.jpg', width = 8, height = 4, units = c("in"),
       dpi = 600)


# Plot projections
ggplot(centroid_annual %>%
         mutate(use_acre_feet = ifelse(use_acre_feet == 0, NA,
                                       use_acre_feet))) +
  geom_line(aes(x = y, y = MLR_demandA_fit, color = cf)) +
  geom_ribbon(aes(x = y, ymin =  MLR_demandA_lwr, ymax =  MLR_demandA_upr, 
              color = cf, fill = cf), alpha = 0.2, linewidth = 0) + 
  geom_line(aes(x = y, 
                y = use_acre_feet),
                color = "black") + 
  scale_color_manual("Modeled", values = c("hotpink","red","dodgerblue4")) +
  scale_fill_manual("Modeled", values = c("hotpink","red","dodgerblue4")) +
  labs(x = "", y = "Annual Water Demand (af)") + 
  xlim(1980,2080) + ylim(-100,350) + theme_bw()

#ggsave('data/Test_Figures/Demand_Projected_Model_Annual_model.jpg', width = 8, height = 4, units = c("in"),
#       dpi = 600)

# Plot Monthly

ggplot(centroid_monthly) +
  geom_line(data = centroid_monthly,aes(x = ym, y = MLR_demand_fit, color = cf)) +
  geom_ribbon(data = centroid_monthly,aes(x = ym, ymin =  MLR_demand_lwr, ymax =  MLR_demand_upr, 
              fill = cf), alpha = 0.6, linewidth = 0) + 
  geom_line(data = centroid_monthly %>% filter(year(ym)<2023),
            aes(x = ym, 
                y = use_acre_feet, 
                color = gcm)) + 
  scale_color_manual("", values = c("black","hotpink","red","dodgerblue4")) +
  scale_fill_manual("",values = c("hotpink","red","dodgerblue4")) +
  labs(x = "", y = "Monthly Water Demand (af)") + 
  theme_bw() #+ scale_y_log10() 

#ggsave('data/Test_Figures/Demand_Projected_Model_Monthly_model.jpg', width = 8, height = 4, units = c("in"),
 #      dpi = 600)


# Calculate stats for monthly per person demand for years 2000-2023. Note,
# historic data only
monthly_pp_demand <- centroid_monthly %>%
  dplyr::filter(year(ym) > 2000) %>%
  drop_na(demand_pp_gal) %>%
  mutate(use_gal = use_acre_feet * 325851) %>%
  dplyr::summarize(sens_slope = trend::sens.slope(demand_pp_gal)$estimates[1],
                   pval = trend::sens.slope(demand_pp_gal)$p.value,
                   mean = mean(demand_pp_gal)) %>%
  mutate(percent_chg = 100 * sens_slope / mean,
    text = case_when(sens_slope < 0 & pval < 0.05 ~ paste0("reduced on average by ",round(percent_chg,1),"% per-person per-year.  These reductions likely reflect successful conservation efforts."),
                          sens_slope > 0 & pval < 0.05 ~ paste0("increased on average by ",round(percent_chg,1)," % per year.  These increases may indicate a need to fortify conservation efforts and focus on inefficiencies in the system."),
                          sens_slope == 0 | pval > 0.05 ~ "did not significantly change."))

# Calculate stats summary for annual water use / demand. For historic, only use
# years 2000-2023 to avoid non-linear trends from too far back.
annual_use_summary <- centroid_annual %>%
  dplyr::select(y,cf,demand_all) %>%
  #dplyr::filter(y >= 2000) %>%
  mutate(demand_gal = demand_all * 325851) %>%
  group_by(cf) %>%
  drop_na(demand_all) %>%
  dplyr::summarize(sens_slope = trend::sens.slope(demand_gal)$estimates[1],
                   pval = trend::sens.slope(demand_gal)$p.value,
                   mean = mean(demand_gal)) %>%
  mutate(percent_chg = 100 * sens_slope / mean,
    text = case_when(sens_slope < 0 & pval < 0.05 ~ paste0("decreased on average by ",round(percent_chg,1)," % per year"),
                          sens_slope > 0 & pval < 0.05 ~ paste0("increased on average by ",round(percent_chg,1)," % per year"),
                          sens_slope == 0 | pval > 0.05 ~ "though the long term trend was neither increasing nor decreasing."))

```

Now calculate vulnerability.

```{r}
# Notes
### ADD frequency counts
### ADD black swan events

# water vulnerability is an imbalance between the supply and demand of water 
# resources within a region over a certain time.

# watershed area + conversion factors 
ws_a_c <- 1550*as.numeric(watersupply_watershed_area) * 1.32852e-8

# vulnerability = watersupply_watershed_area * runoff / demand
centroid_annual <- centroid_annual %>%
  mutate(S_D_ratio = 
           case_when(y <= 2023 ~ ws_a_c * runoff_in / use_acre_feet, 
                     y > 2023 ~ ws_a_c * runoff_in / MLR_demandA_fit),
         S_D_ratio_lwr = case_when(y <= 2023 ~ NA,
                                   y > 2023 ~  ws_a_c * runoff_in / MLR_demandA_lwr),
         S_D_ratio_upr = case_when(y <= 2023 ~ NA,
                                   y > 2023 ~ ws_a_c * runoff_in / MLR_demandA_upr))


# Calculate annual trends in the SD Ratio
annual_SD_summary <- centroid_annual %>%
  dplyr::select(y,cf,S_D_ratio) %>%
  dplyr::filter(y >= 2000) %>%
  group_by(cf) %>%
  drop_na(S_D_ratio) %>%
  dplyr::summarize(sens_slope = trend::sens.slope(S_D_ratio)$estimates[1],
                   pval = trend::sens.slope(S_D_ratio)$p.value,
                   mean = mean(S_D_ratio)) %>%
  mutate(text = case_when(sens_slope < 0 & pval < 0.05 ~ paste0("decreasing at a rate of ", round(sens_slope,5), " units per year"),
                          sens_slope > 0 & pval < 0.05 ~ paste0("increasing at a rate of ", round(sens_slope,5), " units per year"),
                          sens_slope == 0 | pval > 0.05 ~ "not significantly changing"),
         percent_chg = 100*sens_slope/mean)


centroid_monthly <- centroid_monthly %>%
  mutate(S_D_ratio = 
           case_when(year(ym) <= 2023 ~ ws_a_c * runoff_in / use_acre_feet, 
                     year(ym) > 2023 ~ ws_a_c * runoff_in / MLR_demand_fit),
         S_D_ratio_lwr = 
           case_when(year(ym) <= 2023 ~ NA,
                     year(ym) > 2023 ~ ws_a_c * runoff_in / MLR_demand_lwr),
         S_D_ratio_upr = 
           case_when(year(ym) <= 2023 ~ NA,
                     year(ym) > 2023 ~ ws_a_c * runoff_in / MLR_demand_upr))
         
# Plot monthly
ggplot(centroid_monthly,
       aes(x = ym, y = S_D_ratio, color = cf, fill = cf)) + 
  geom_point() + 
  geom_smooth() + 
  scale_color_manual("", values = c("darkgray","red","dodgerblue")) +
  scale_fill_manual("", values = c("darkgray","red","dodgerblue")) +
  ylim(0,100) +
  theme_bw() +
  labs(x = "", y = "Monthly S-D Ratio")
#ggsave('data/Test_Figures/S-D_Ratio_Monthly.jpg', width = 8, height = 2, units = c("in"),
#       dpi = 600)

ggplot(centroid_annual) +
  #geom_line(aes(x = y, y = S_D_ratio, color = cf),size = 1) +
  geom_point(aes(x = y, y = S_D_ratio, color = cf)) +
  geom_ribbon(aes(x = y, ymin =  S_D_ratio_lwr, ymax =  S_D_ratio_upr, 
              color = cf, fill = cf), alpha = 0.2, linewidth = 0) + 
  geom_smooth(aes(x = y, y = S_D_ratio, color = cf), method = "lm") +
  scale_color_manual("", values = c("darkgray","red","dodgerblue")) +
  scale_fill_manual("", values = c("darkgray","red","dodgerblue")) +
  labs(x = "", y = "Annual S-D Ratio") + 
   ylim(0,1) + theme_bw()
#ggsave('data/Test_Figures/S-D_Ratio_Annual.jpg', width = 8, height = 2, units = c("in"),
#       dpi = 600)

```

###### 4.5 Magnitude Stats

The magnitude of annual change is an important indicator of trends at parks. This section calculates the Sen's slope for each variable with associated metrics for whether this trend is significant.

```{r}

# magnitude df containing the magnitude and direction of change through time for
# each variable as Sen's slope. Note, slope represents degrees farenheit change
# per year for temperature variables, change in days per year for day-count 
# variables, and change gallons per year for water balance terms. Because
# WBM variables are input as length per time (inches-per-year in this case),
# L/T is converted to volume-per-time as gallons per year by multiplying the
# inches-per-time value by the area of the watersupply watershed and a convers-
# ion factor (1550 (in2 per m2) * 0.004329 (in3 per gallon)).

#  Watershed area in gallons / in (for conversion after)
 wsg<- as.numeric(watersupply_watershed_area) * 1550 * 0.004329

magnitude <- centroid_annual %>%
  ungroup() %>%
  dplyr::select(-c(unit_climate_zone, gcm)) %>%
  # Define specific columns to calculate magnitude
  dplyr::select(y, cf, precip_in, rain_in, aet_in, pet_in, days_gt_92F, 
                days_lt_32F, days_gt_95pcp, days_gt_95roff, days_gt_77F,
                days_lt_05roff, days_w_pcp, days_w_swe, tavg_f, tmax_f,
                tmin_f, r_hmax_percent, r_hmin_percent, deficit_in, 
                soil_water_in, runoff_in, accumswe_in, snow_in, peak_swe_in,
                peak_runoff_in, TotalVisitors_all, demand_all, S_D_ratio) %>%
  pivot_longer(cols = -c(y,cf),names_to = "vars", values_to = "vals") %>%
  group_by(cf,vars) %>%
  # For linear method slope, uncomment:
  #dplyr::summarize(slope = round(coef(lm(vals ~ y))[2],3), 
  #.groups = "keep") %>%
  dplyr::summarize(slope = trend::sens.slope(vals[!is.na(vals)])$estimates,
                   pval = trend::sens.slope(vals[!is.na(vals)])$p.value,
                   .groups = "keep") %>%
  mutate(dir = case_when(slope < 0 & pval < 0.05 ~"decreases",
                         slope > 0 & pval < 0.05 ~"increases",
                         slope == 0 | pval >= 0.05  ~ "no significant changes"),
         slope = case_when(pval < 0.05 ~ slope,
                           pval >= 0.05 ~ 0))


# Create dataframe containing the percentage change that occurs from historic 
# to future time periods

annual_percent_change <- (100*(annual_stats[2:3,3:ncol(annual_stats)] -           
                       annual_stats[rep(1,2),3:ncol(annual_stats)]) / 
                       annual_stats[rep(1,2),3:ncol(annual_stats)]) %>%
                      cbind(annual_stats[2:3,1:2],.)

```


Save data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# save_variables <- c("park_name", "report_name", "runoff_magnitude", 
#                     "spring_runoff_yearly_change", "park_boundary",
#                     "centroid_annual", "centroid_monthly",
#                     "visitor_2013_2023_change", "visitor_2043_2053_change")


## path to data folder (from project directory)
#out_path <- paste0("data/park/",park,"/",park,"_report2_data.RData")

# save(list = save_variables, 
#      file = out_path)

# for now, just saving everything created in this document while deciding what to use in the report
#save.image(out_path)


```

